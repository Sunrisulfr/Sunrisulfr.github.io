<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>确定性策略梯度DDPG</title>
    <url>/2021/01/03/DDPG/</url>
    <content><![CDATA[<p>DDPG是google DeepMind团队提出的一种用于输出确定性动作的算法，它解决了Actor-Critic 神经网络每次参数更新前后都存在相关性，导致神经网络只能片面的看待问题这一缺点。同时也解决了DQN不能用于连续性动作的缺点。</p>
<p>论文链接：<a href="https://arxiv.org/pdf/1509.02971.pdf">https://arxiv.org/pdf/1509.02971.pdf</a></p>
<h1 id="确定性策略"><a href="#确定性策略" class="headerlink" title="确定性策略"></a>确定性策略</h1><p>确定性策略是和随机策略相对而言的，对于某一些动作集合来说，它可能是连续值，或者非常高维的离散值，这样动作的空间维度极大。如果我们使用随机策略，即像DQN一样研究它所有的可能动作的概率，并计算各个可能的动作的价值的话，那需要的样本量是非常大才可行的。于是有人就想出使用确定性策略来简化这个问题。</p>
<p>作为随机策略，在相同的策略，在同一个状态处，采用的动作是基于一个概率分布的，即是不确定的。而确定性策略则决定简单点，虽然在同一个状态处，采用的动作概率不同，但是最大概率只有一个，如果我们只取最大概率的动作，去掉这个概率分布，那么就简单多了。即作为确定性策略，相同的策略，在同一个状态处，动作是唯一确定的，即策略变成 $\pi_\theta(s) = a$。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLPActorCritic</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, observation_space, action_space, hidden_sizes=(<span class="params"><span class="number">256</span>,<span class="number">256</span></span>),</span></span></span><br><span class="line"><span class="function"><span class="params">                 activation=nn.ReLU</span>):</span></span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">        obs_dim = observation_space.shape[<span class="number">0</span>]</span><br><span class="line">        act_dim = action_space.shape[<span class="number">0</span>]</span><br><span class="line">        act_limit = action_space.high[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># build policy and value functions</span></span><br><span class="line">        self.pi = MLPActor(obs_dim, act_dim, hidden_sizes, activation, act_limit)</span><br><span class="line">        self.q = MLPQFunction(obs_dim, act_dim, hidden_sizes, activation)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">act</span>(<span class="params">self, obs</span>):</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">return</span> self.pi(obs).numpy()</span><br></pre></td></tr></table></figure>
<p>理由：</p>
<ul>
<li>即使通过PG学习得到了随机策略之后，在每一步行为时，我们还需要对得到的最优策略概率分布进行采样，才能获得action的具体值；而action通常是高维的向量，比如25维、50维，在高维的action空间的频繁采样，无疑是很耗费计算能力的；</li>
<li>在PG的学习过程中，每一步计算policy gradient都需要在整个action space进行积分。</li>
</ul>
<h1 id="DPG到DDPG"><a href="#DPG到DDPG" class="headerlink" title="DPG到DDPG"></a>DPG到DDPG</h1><p>使用卷积神经网络来模拟策略函数和Q函数，并用深度学习的方法来训练，证明了在RL方法中，非线性模拟函数的准确性和高性能、可收敛；</p>
<p>而DPG中，可以看成使用线性回归的机器学习方法：使用带参数的线性函数来模拟策略函数和Q函数，然后使用线性回归的方法进行训练。</p>
<p>experience replay memory的使用：actor同环境交互时，产生的transition数据序列是在时间上高度关联(correlated)的，如果这些数据序列直接用于训练，会导致神经网络的overfit，不易收敛。</p>
<p>DDPG的actor将transition数据先存入experience replay buffer, 然后在训练时，从experience replay buffer中随机采样mini-batch数据，这样采样得到的数据可以认为是无关联的。</p>
<p>target 网络和online 网络的使用， 使的学习过程更加稳定，收敛更有保障。</p>
<h2 id="实现框架"><a href="#实现框架" class="headerlink" title="实现框架"></a>实现框架</h2><p><img src="/2021/01/03/DDPG/Framework.PNG" alt="framwork"></p>
<h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p><img src="/2021/01/03/DDPG/Algorithm.PNG" alt="algorithm"></p>
<h2 id="Exploration"><a href="#Exploration" class="headerlink" title="Exploration"></a>Exploration</h2><p>DDPG以非策略的方式训练确定性策略。因为策略是确定的，如果agent要探索on-policy，在一开始它可能不会尝试足够广泛的行动来找到有用的学习信号。为了使DDPG政策更好地探索，我们在训练时为他们的行动添加噪音。原始DDPG论文的作者推荐了时间相关的OU噪声，但最近的结果表明，不相关、均值为零的高斯噪声工作得很好。因为后者更简单，所以更可取。为了便于获得高质量的训练数据，您可以在训练过程中减少噪声的规模。(我们在实现中没有这样做，并始终保持噪声规模固定。)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_action</span>(<span class="params">o, noise_scale</span>):</span></span><br><span class="line">        a = ac.act(torch.as_tensor(o, dtype=torch.float32))</span><br><span class="line">        a += noise_scale * np.random.randn(act_dim)</span><br><span class="line">        <span class="keyword">return</span> np.clip(a, -act_limit, act_limit)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Generative Adversarial Imitation Learning (GAIL)</title>
    <url>/2022/01/03/GAIL/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>论文：<a href="https://arxiv.org/abs/1606.03476">https://arxiv.org/abs/1606.03476</a><br>本文要解决的是Imitation Learning和Inverse RL。基本思想比较简单，利用GAN的对抗训练来生成给定的专家数据分布。为什么要用GAN，作者提出，一般Imitation Learning传统的Behavioral Cloning的方法存在状态漂移的问题，一旦遇到没有在专家轨迹中出现的状态将会产生很大的误差以及累计误差；此外，Inverse RL逆强化学习的方法把强化学习的学习过程套在求解cost function的过程中，因此效率很低；然后，逆强化学习只学到的cost function只是解释了专家轨迹，但没有学习到策略，而利用GAIL可以直接显式的得到决策，更高效。</p>
<p>GAIL的核心在于，尽管使用了对抗的思想，但并没有显式的Generator在其中，充当Generator作用的是智能体的Policy。GAIL的学习大致分为两步，第一步通过当前policy采样得到的数据与专家数据进行对抗训练来训练Discriminator；然后，利用Discriminator作为surrogate reward function来训练策略Policy，文章使用的TRPO。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode 日记：剑指offer篇</title>
    <url>/2022/03/01/Leetcode/</url>
    <content><![CDATA[<p>我真的不想刷题！！ T_T</p>
<h1 id="剑指-Offer-33-二叉搜索树的后序遍历序列"><a href="#剑指-Offer-33-二叉搜索树的后序遍历序列" class="headerlink" title="剑指 Offer 33. 二叉搜索树的后序遍历序列"></a>剑指 Offer 33. 二叉搜索树的后序遍历序列</h1><h2 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h2><p>输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历结果。如果是则返回 true，否则返回 false。假设输入的数组的任意两个数字都互不相同。</p>
<p>参考以下这颗二叉搜索树：</p>
<pre><code>    5
   / \
  2   6
 / \
1   3
</code></pre><p>示例 1：</p>
<p>输入: [1,6,3,2,5]<br>输出: false</p>
<p>示例 2：</p>
<p>输入: [1,3,2,6,5]<br>输出: true</p>
<h2 id="code"><a href="#code" class="headerlink" title="code"></a>code</h2><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="comment">// 单调栈</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">verifyPostorder</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; postorder)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; s;</span><br><span class="line">        <span class="keyword">int</span> root = INT_MAX;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = postorder.size() - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--)&#123;</span><br><span class="line">            <span class="keyword">if</span>(postorder[i] &gt; root)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">while</span>(!s.empty() &amp;&amp; postorder[i] &lt; s.top())&#123;</span><br><span class="line">                root = s.top();</span><br><span class="line">                s.pop();</span><br><span class="line">            &#125;</span><br><span class="line">            s.push(postorder[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="剑指-Offer-36-二叉搜索树与双向链表"><a href="#剑指-Offer-36-二叉搜索树与双向链表" class="headerlink" title="剑指 Offer 36. 二叉搜索树与双向链表"></a>剑指 Offer 36. 二叉搜索树与双向链表</h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><p>输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的循环双向链表。要求不能创建任何新的节点，只能调整树中节点指针的指向。</p>
<p>code<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Node *pre = <span class="literal">nullptr</span>, *head = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(Node* root)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(!root) <span class="keyword">return</span>;</span><br><span class="line">        dfs(root -&gt; left);</span><br><span class="line">        <span class="keyword">if</span> (pre) pre-&gt;right = root;</span><br><span class="line">        <span class="keyword">else</span> head = root; <span class="comment">// 保存链表头结点</span></span><br><span class="line">        root-&gt;left = pre; </span><br><span class="line">        pre = root;</span><br><span class="line">        dfs(root-&gt;right); <span class="comment">//右子树</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">Node* <span class="title">treeToDoublyList</span><span class="params">(Node* root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!root) <span class="keyword">return</span> root;</span><br><span class="line">        dfs(root);</span><br><span class="line">        head-&gt;left = pre;</span><br><span class="line">        pre-&gt;right = head;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<h1 id="剑指-Offer-II-078-合并排序链表"><a href="#剑指-Offer-II-078-合并排序链表" class="headerlink" title="剑指 Offer II 078. 合并排序链表"></a>剑指 Offer II 078. 合并排序链表</h1><h2 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h2><p>给定一个链表数组，每个链表都已经按升序排列。<br>请将所有链表合并到一个升序链表中，返回合并后的链表。</p>
 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">cmp</span>&#123;</span></span><br><span class="line">        <span class="function"><span class="keyword">bool</span> <span class="title">operator</span><span class="params">()</span> <span class="params">(ListNode* a, ListNode* b)</span></span>&#123;</span><br><span class="line">            <span class="keyword">return</span> a -&gt; val &gt; b -&gt; val;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="function">ListNode* <span class="title">mergeKLists</span><span class="params">(<span class="built_in">vector</span>&lt;ListNode*&gt;&amp; lists)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">priority_queue</span>&lt;ListNode *, <span class="built_in">vector</span>&lt;ListNode *&gt;, cmp&gt; pq;</span><br><span class="line">        ListNode* dummy = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">auto</span> p : lists)&#123;</span><br><span class="line">            <span class="keyword">if</span>(p) pq.push(p);</span><br><span class="line">        &#125;</span><br><span class="line">        ListNode* t = dummy;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(!pq.empty())&#123;</span><br><span class="line">            t -&gt; next = pq.top();</span><br><span class="line">            t = pq.top();</span><br><span class="line">            pq.pop();</span><br><span class="line">            <span class="keyword">if</span>(t-&gt;next)&#123;</span><br><span class="line">                pq.push(t-&gt;next);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dummy-&gt;next;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="剑指-Offer-II-106-二分图"><a href="#剑指-Offer-II-106-二分图" class="headerlink" title="剑指 Offer II 106. 二分图"></a>剑指 Offer II 106. 二分图</h1> <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isBipartite</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; graph)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = graph.size();</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">color</span><span class="params">(n, <span class="number">0</span>)</span></span>;</span><br><span class="line">        <span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; q;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(!color[i])&#123;</span><br><span class="line">                q.push(i);</span><br><span class="line">                color[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">while</span>(!q.empty())&#123;</span><br><span class="line">                <span class="keyword">int</span> node = q.front();</span><br><span class="line">                q.pop();</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">const</span> <span class="keyword">int</span> &amp; j : graph[node])&#123;</span><br><span class="line">                    <span class="keyword">if</span>(color[j] == <span class="number">0</span>)&#123;</span><br><span class="line">                        color[j] = color[node] == <span class="number">2</span> ? <span class="number">1</span> : <span class="number">2</span>;</span><br><span class="line">                        q.push(j);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(color[node] == color[j])</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>题</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>Soft Actor Critic (SAC)</title>
    <url>/2021/01/20/SAC/</url>
    <content><![CDATA[<p>SAC (Soft Actor Critic)是一种对随机策略进行非策略优化的算法，在随机策略优化和ddpg方法之间架起了一座桥梁。它并不是TD3的直接继承者(几乎是同时发布的)，但它包含了短双q技巧，并且由于SAC政策的固有随机性，它也最终受益于目标政策平滑之类的东西。</p>
<p>SAC的一个中心特征是熵正则化。该策略被训练成最大化期望收益和熵之间的权衡，熵是该策略中随机性的度量。这与探索-利用的权衡关系密切:熵的增加会导致更多的探索，从而加速以后的学习。它还可以防止策略过早地收敛到一个坏的局部最优。</p>
<h1 id="Entropy-Regularized-Reinforcement-Learning"><a href="#Entropy-Regularized-Reinforcement-Learning" class="headerlink" title="Entropy-Regularized Reinforcement Learning"></a>Entropy-Regularized Reinforcement Learning</h1><p>Entropy is a quantity which, roughly speaking, says how random a random variable is. If a coin is weighted so that it almost always comes up heads, it has low entropy; if it’s evenly weighted and has a half chance of either outcome, it has high entropy.</p>
<p>Let x be a random variable with probability mass or density function P. The entropy H of x is computed from its distribution P according to</p>
<script type="math/tex; mode=display">
H(P) = \mathop{\text{E}}\limits_{x\sim P}[-\log P(x)].</script><p>在熵正则化强化学习中，agent在每个时间步上获得的奖励与策略在该时间步上的熵成正比。这将RL问题改变为:</p>
<script type="math/tex; mode=display">
\pi^* = \arg \max_{\pi} \mathop{\text{E}}\limits_{\tau \sim \pi}{ \sum_{t=0}^{\infty} \gamma^t \bigg( R(s_t, a_t, s_{t+1}) + \alpha H\left(\pi(\cdot|s_t)\right) \bigg)},</script><p>其中$\alpha &gt; 0$是权衡系数。(注意:我们在这里假设一个无限视界贴现设置，我们将在本页面的其余部分做同样的事情。)现在我们可以在这个设置中定义稍微不同的值函数。$V^{\pi}$被修改为包含每个时间步的熵加成:</p>
<script type="math/tex; mode=display">V^{\pi}(s) = \mathop{\text{E}}\limits_{\tau \sim \pi} \Bigg [ \left. \sum_{t=0}^{\infty} \gamma^t \bigg( R(s_t, a_t, s_{t+1}) + \alpha H\left(\pi(\cdot|s_t)\right) \bigg) \right| s_0 = s \Bigg ]</script><p>$Q^{\pi}$被修改为包含除了第一个时间步之外的每个时间步的熵奖励:</p>
<script type="math/tex; mode=display">Q^{\pi}(s,a) = \mathop{\text{E}}\limits_{\tau \sim \pi}{ \Bigg [\left. \sum_{t=0}^{\infty} \gamma^t  R(s_t, a_t, s_{t+1}) + \alpha \sum_{t=1}^{\infty} \gamma^t H\left(\pi(\cdot|s_t)\right)\right| s_0 = s, a_0 = a}\Bigg ]</script><p>有了这些定义，$V^{\pi}$和$Q^{\pi}$之间是这样连接的:</p>
<script type="math/tex; mode=display">
V^\pi(s) = \mathop{\text{E}}\limits_{a \sim \pi}[Q^\pi(s,a)] + \alpha H(\pi(\cdot | s))</script><p>$Q^{\pi}$的Bellman方程为:</p>
<script type="math/tex; mode=display">
Q^{\pi}(s,a) = \mathop{\text{E}}\limits_{s' \sim P,  a' \sim \pi}{R(s,a,s') + \gamma\left(Q^{\pi}(s',a') + \alpha H\left(\pi(\cdot|s')\right) \right)} \\
= \mathop{\text{E}}\limits_{s' \sim P}{R(s,a,s') + \gamma V^{\pi}(s')}.</script><h1 id="Soft-Actor-critic"><a href="#Soft-Actor-critic" class="headerlink" title="Soft Actor-critic"></a>Soft Actor-critic</h1><p>SAC同时学习一个策略$pi<em>{\ θ}$和两个$q$函数$Q</em>{\phi<em>1}$，$Q</em>{\phi_2}$。目前标准的SAC有两种变体:一种使用固定的熵正则化系数$\alpha$，另一种通过在培训过程中改变$\alpha$来强制熵约束。</p>
<h1 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h1><p><img src="/2021/01/20/SAC/Algorithm.svg" alt="algorithm"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>off-policy</tag>
      </tags>
  </entry>
  <entry>
    <title>Twin Delayed DDPG (TD3)</title>
    <url>/2021/01/10/TD3/</url>
    <content><![CDATA[<p>虽然DDPG有时可以获得很好的性能，但对于超参数和其他类型的调优，它经常是脆弱的。DDPG最常见的失效模式是学习后的q函数开始大幅高估q值，从而导致策略失效，因为它利用了q函数中的错误。Twin Delayed DDPG (TD3)是一种通过引入三个关键技巧来解决这个问题的算法:</p>
<ul>
<li><strong>Clipped Double Q-learning</strong>: TD3学习两个q函数而不是一个(因此称为“Twin”)，并使用两个q值中较小的一个来形成Bellman误差损失函数中的目标。</li>
<li><strong>“Delayed Policy Update</strong>: TD3更新策略(和目标网络)的频率低于q函数。比如，每两个q函数更新进行一次策略更新。</li>
<li><strong>Target Policy Smoothing</strong>: TD3向目标动作添加噪声，使策略更难利用Q函数错误，方法是使Q沿着动作的变化平滑。</li>
</ul>
<h1 id="Key-Equations"><a href="#Key-Equations" class="headerlink" title="Key Equations"></a>Key Equations</h1><h2 id="Target-Policy-Smoothing"><a href="#Target-Policy-Smoothing" class="headerlink" title="Target Policy Smoothing"></a>Target Policy Smoothing</h2><p>用于形成q学习目标的动作是基于目标策略，$\mu<em>{\theta</em>{\text{targ}}} $，但是在动作的每个维度上都添加了剪切噪声。在添加了被剪辑的噪声之后，目标动作就会被剪辑到有效的动作范围内(所有有效的动作$a$，满足$a<em>{Low} \leq a \leq a</em>{High}$)。目标操作如下:</p>
<script type="math/tex; mode=display">
a'(s') = \text{clip}\left(\mu_{\theta_{\text{targ}}}(s') + \text{clip}(\epsilon,-c,c), a_{Low}, a_{High}\right), \;\; \epsilon \sim \mathcal{N}(0, \sigma))</script><p>目标策略平滑实质上是算法的正则化。它解决了DDPG中可能发生的特定失效模式:如果q函数近似器为某些动作开发了一个不正确的尖峰，策略将迅速利用该尖峰，然后产生脆弱或不正确的行为。这可以通过平滑类似行为的q函数来避免，这是政策平滑的目标。</p>
<h2 id="Clipped-Double-Q-learning"><a href="#Clipped-Double-Q-learning" class="headerlink" title="Clipped Double Q-learning"></a>Clipped Double Q-learning</h2><p>两个q函数都使用一个目标，使用两个q函数中的任意一个计算出一个较小的目标值:</p>
<script type="math/tex; mode=display">
y(r,s',d) = r + \gamma (1 - d) \min_{i=1,2} Q_{\phi_{i, \text{targ}}}(s', a'(s'))</script><p>然后他们都通过回归这个目标来学习：</p>
<script type="math/tex; mode=display">
L(\phi_1, {\mathcal D}) = \mathop{E}\limits_{(s,a,r,s',d) \sim {\mathcal D}}{\Bigg( Q_{\phi_1}(s,a) - y(r,s',d) \Bigg)^2},</script><script type="math/tex; mode=display">
L(\phi_2, {\mathcal D}) = \mathop{E}\limits_{(s,a,r,s',d) \sim {\mathcal D}}{\Bigg( Q_{\phi_2}(s,a) - y(r,s',d) \Bigg)^2}.</script><p>为目标使用较小的q值，并向其回归，有助于避免q函数中的过高估计。</p>
<p>最后:通过最大化$Q_{\phi_1}$来学习策略:</p>
<script type="math/tex; mode=display">
\max_{\theta} \mathop{E}\limits_{s \sim {\mathcal D}}\left[ Q_{\phi_1}(s, \mu_{\theta}(s)) \right]</script><p>这和DDPG几乎没有什么区别。然而，在TD3中，策略的更新频率低于q函数。这有助于抑制DDPG中由于策略更新更改目标的方式而出现的波动性。</p>
<h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><p><img src="/2021/01/10/TD3/TD3Algorithm.svg" alt="Algorithm"></p>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Actor</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, state_dim, action_dim, max_action</span>):</span></span><br><span class="line">        super(Actor, self).__init__()</span><br><span class="line">        self.f1 = nn.Linear(state_dim, <span class="number">256</span>)</span><br><span class="line">        self.f2 = nn.Linear(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.f3 = nn.Linear(<span class="number">128</span>, action_dim)</span><br><span class="line">        self.max_action = max_action</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.f1(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.f2(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.f3(x)</span><br><span class="line">        <span class="keyword">return</span> torch.tanh(x) * self.max_action</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Critic</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, state_dim, action_dim</span>):</span></span><br><span class="line">        super(Critic,self).__init__()</span><br><span class="line">        self.f11 = nn.Linear(state_dim+action_dim, <span class="number">256</span>)</span><br><span class="line">        self.f12 = nn.Linear(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.f13 = nn.Linear(<span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.f21 = nn.Linear(state_dim + action_dim, <span class="number">256</span>)</span><br><span class="line">        self.f22 = nn.Linear(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.f23 = nn.Linear(<span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, state, action</span>):</span></span><br><span class="line">        sa = torch.cat([state, action], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = self.f11(sa)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.f12(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        Q1 = self.f13(x)</span><br><span class="line"></span><br><span class="line">        x = self.f21(sa)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.f22(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        Q2 = self.f23(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Q1, Q2</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">self.actor = Actor(self.state_dim, self.action_dim, self.max_action)</span><br><span class="line">self.target_actor = copy.deepcopy(self.actor)</span><br><span class="line">self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=<span class="number">3e-4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">self.critic = Critic(self.state_dim, self.action_dim)</span><br><span class="line">self.target_critic = copy.deepcopy(self.critic)</span><br><span class="line">self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=<span class="number">3e-4</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">learn</span>(<span class="params">self</span>):</span></span><br><span class="line">       self.total_it += <span class="number">1</span></span><br><span class="line">       data = self.buffer.smaple(size=<span class="number">128</span>)</span><br><span class="line">       state, action, done, state_next, reward = data</span><br><span class="line">       <span class="keyword">with</span> torch.no_grad:</span><br><span class="line">           noise = (torch.rand_like(action) * self.policy_noise).clamp(-self.noise_clip, self.noise_clip)</span><br><span class="line">           next_action = (self.target_actor(state_next) + noise).clamp(-self.max_action, self.max_action)</span><br><span class="line">           target_Q1,target_Q2 = self.target_critic(state_next, next_action)</span><br><span class="line">           target_Q = torch.min(target_Q1, target_Q2)</span><br><span class="line">           target_Q = reward + done * self.discount * target_Q</span><br><span class="line">       current_Q1, current_Q2 = self.critic(state, action)</span><br><span class="line">       critic_loss = F.mse_loss(current_Q1, target_Q) + F.mse_loss(current_Q2, target_Q)</span><br><span class="line">       critic_loss.backward()</span><br><span class="line">       self.critic_optimizer.step()</span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span> self.total_it % self.policy_freq == <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">           q1,q2 = self.critic(state, self.actor(state))</span><br><span class="line">           actor_loss = -torch.min(q1, q2).mean()</span><br><span class="line"></span><br><span class="line">           self.actor_optimizer.zero_grad()</span><br><span class="line">           actor_loss.backward()</span><br><span class="line">           self.actor_optimizer.step()</span><br><span class="line">           <span class="keyword">for</span> param, target_param <span class="keyword">in</span> zip(self.critic.parameters(), self.target_critic.parameters()):</span><br><span class="line">               target_param.data.copy_(self.tau * param.data + (<span class="number">1</span> - self.tau) * target_param.data)</span><br><span class="line"></span><br><span class="line">           <span class="keyword">for</span> param, target_param <span class="keyword">in</span> zip(self.actor.parameters(), self.target_actor.parameters()):</span><br><span class="line">               target_param.data.copy_(self.tau * param.data + (<span class="number">1</span> - self.tau) * target_param.data)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>AlphaGO：详解</title>
    <url>/2020/12/31/alphago/</url>
    <content><![CDATA[<h1 id="了解AlphaGO"><a href="#了解AlphaGO" class="headerlink" title="了解AlphaGO"></a>了解AlphaGO</h1><!-- ![Ray_head_logo](AlphaGO/AlphaGo.jpg) -->
<h2 id="选出好棋-增强学习Reinforcement-Learning"><a href="#选出好棋-增强学习Reinforcement-Learning" class="headerlink" title="选出好棋-增强学习Reinforcement Learning"></a>选出好棋-增强学习Reinforcement Learning</h2><p><img src="/2020/12/31/alphago/Network.PNG" alt="Network"></p>
<h3 id="模仿学习"><a href="#模仿学习" class="headerlink" title="模仿学习"></a>模仿学习</h3><h3 id="增强学习"><a href="#增强学习" class="headerlink" title="增强学习"></a>增强学习</h3><p><img src="/2020/12/31/alphago/RL.PNG" alt="RL"></p>
<h2 id="“手下一步棋，心想三步棋”-蒙特卡罗树MCTS"><a href="#“手下一步棋，心想三步棋”-蒙特卡罗树MCTS" class="headerlink" title="“手下一步棋，心想三步棋”-蒙特卡罗树MCTS"></a>“手下一步棋，心想三步棋”-蒙特卡罗树MCTS</h2><p>围棋问题实际上是一个树的搜索问题，当前局面是树的根，树根有多少分支，对应着下一步有多少对应的落子，这是树的宽度。之后树不断的生长（推演，模拟），直到叶子节点（开始落子）。从树根到叶子节点，分了多少次枝就是树的深度。树的广度越宽，深度越深，搜索所需要的时间越长。如：围棋一共361个交叉点，越往后，可以落子的位子越少，所以平均下来树的宽度大约为250，深度大约150.如果想遍历整个围棋树，需要搜索250的150次方。所以走一步前，需要搜索折磨多次数是不切实际的。</p>
<p>每次AlphaGo都会自己和自己下棋，每一步都由一个函数决定应该走哪一步，它会考虑如下几个点：</p>
<p>1.这个局面大概该怎么下？（使用SL Policy network）</p>
<p>2.下一步会导致什么样的局面？</p>
<p>3.我赢的概率是多少？（使用Value network+rollout）</p>
<p>首先，“走棋网络”是训练的当前局面s的下一步走棋位置的概率分布，它模拟的是在某个局面下，人类的常见的走棋行为，并不评估走棋之后是否赢棋（区别概率分布与赢棋的概率？）。所以，我们可以假设优秀的走棋方法是在人类常见的走棋范围内的，这样就大大减少了搜索树的宽度。</p>
<p>这时候，使用SL policy network 完成了第一落子，假设走了a1之后，然后对方开始走a2，接着我在走a3.这样一步步的模拟下去…..(这里使用两个SL policy network的自我对弈)假设V(s,a1)赢棋的概率为70%,对方走了V(s,a1,a2)对方赢棋的概率为60%。而走到第三步的时候，我方的赢棋概率V(s,a1,a2,a3)是35%，这时候还要不要在走a1呢？</p>
<p>重新定义V(s)的实际意义：它用来预测该局面以监督学习的策略网络（SL Policy network）自我对弈后赢棋的概率,也就是模拟N次后，AlphaGo认为她走这步棋赢的概率，这个概率是不断的更新。我们用V<em>表示某一局面赢棋的概率。刚开始v</em>(s,a1)=70%,在下完第三步后更新为v*(s,a1)=(70%-60%+35%)/3=15%，这个时候V(s,a1)=15%，已经不是之前的70%了，也就是说这个位置可能不是赢棋的概率最大的位置，所以舍弃。</p>
<p>然而发现，SL Policy network 来进行自我对弈太慢了(3毫秒)，重新训练了一个mini的SL Policy network，叫做rollout(2微秒). 它的输入比policy network 小，它的模型也小，它没有Policy network 准，但是比他快。</p>
<p>这就是蒙特卡罗树搜索的基本过程，</p>
<p>1.它首先使用SL policy network选出可能的落子区域，中间开始使用value network来选择可能的落子区域。</p>
<p>2.使用快速走子（Fast rollout）来适当牺牲走棋质量的条件下，通过Fast rollout的自我对弈（快速模拟）出最大概率的落子方案，使得AlphaGo 能够看到未来。</p>
<p>3.使用Value network对当前形势做一个判断，判断赢的概率，使得AlphaGo能够看到当下。可见，MC树融合了policy network 、Fast rollout和Value network，使之形成一个完整的系统。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>MCTS</tag>
      </tags>
  </entry>
  <entry>
    <title>Ray.Tune初探（一）：分布式超参优化</title>
    <url>/2020/11/03/ray1/</url>
    <content><![CDATA[<h1 id="OVERVIEW-RAY"><a href="#OVERVIEW-RAY" class="headerlink" title="OVERVIEW RAY"></a>OVERVIEW RAY</h1><p><img src="/2020/11/03/ray1/ray_header_logo.png" alt="Ray_head_logo"></p>
<h2 id="What-is-Ray"><a href="#What-is-Ray" class="headerlink" title="What is Ray?"></a>What is Ray?</h2><p><strong>Ray 提供了一个简单的通用 API，用于构建分布式应用程序。</strong></p>
<p>Ray通过以下三步完成此任务：</p>
<ol>
<li>为构建和运行分布式应用程序提供简单的基元。</li>
<li>使最终用户能够并行化单个计算机代码，很少或零更改代码。</li>
<li>在核心 Ray 上包括一个大型应用程序、库和工具生态系统，以启用复杂的应用程序。</li>
</ol>
<p><strong>Ray Core</strong>为应用程序构建提供了简单的基元。</p>
<p>在<strong>Ray Core</strong>的顶部是解决机器学习中问题的几个库：</p>
<ul>
<li><a href="https://docs.ray.io/en/latest/tune/index.html">Tune: Scalable Hyperparameter Tuning</a></li>
<li><a href="https://docs.ray.io/en/latest/rllib.html#rllib-index">RLlib: Scalable Reinforcement Learning</a></li>
<li><a href="https://docs.ray.io/en/latest/raysgd/raysgd.html#sgd-index">RaySGD: Distributed Training Wrappers</a></li>
<li><a href="https://docs.ray.io/en/latest/serve/index.html#rayserve">Ray Serve: Scalable and Programmable Serving</a></li>
</ul>
<h2 id="A-Simple-example"><a href="#A-Simple-example" class="headerlink" title="A Simple example"></a>A Simple example</h2><p>Ray 提供 Python 和 Java API。Ray 使用Tasks（functions）和Actors（Classes）两种形式来允许用户并行化代码。这里给出一个官方文档的Python示例，具体可以见<a href="https://docs.ray.io/en/latest/ray-overview/index.html#gentle-intro">A Gentle Introduction to Ray</a>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># First, run `pip install ray`.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> ray</span><br><span class="line">ray.init()</span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x * x</span><br><span class="line"></span><br><span class="line">futures = [f.remote(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>)]</span><br><span class="line">print(ray.get(futures)) <span class="comment"># [0, 1, 4, 9]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Counter</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.n = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">increment</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.n += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.n</span><br><span class="line"></span><br><span class="line">counters = [Counter.remote() <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>)]</span><br><span class="line">[c.increment.remote() <span class="keyword">for</span> c <span class="keyword">in</span> counters]</span><br><span class="line">futures = [c.read.remote() <span class="keyword">for</span> c <span class="keyword">in</span> counters]</span><br><span class="line">print(ray.get(futures)) <span class="comment"># [1, 1, 1, 1]</span></span><br></pre></td></tr></table></figure>
<h1 id="Waiting-for-Partial-Results"><a href="#Waiting-for-Partial-Results" class="headerlink" title="Waiting for Partial Results"></a>Waiting for Partial Results</h1><p>After launching a number of tasks, you may want to know which ones have finished executing without blocking on all of them, as in ray.get. This can be done with wait (ray.wait). The function works as follows.</p>
<h1 id="Tune-Scalable-Hyperparameter-Tuning"><a href="#Tune-Scalable-Hyperparameter-Tuning" class="headerlink" title="Tune: Scalable Hyperparameter Tuning"></a>Tune: Scalable Hyperparameter Tuning</h1><p><img src="/2020/11/03/ray1/tune_logo.png" alt="tune_logo"></p>
<h2 id="What-is-Ray-tune"><a href="#What-is-Ray-tune" class="headerlink" title="What is Ray.tune?"></a>What is Ray.tune?</h2><p>Tune is a Python library for experiment execution and hyperparameter tuning at any scale. Core features:</p>
<ul>
<li>Launch a multi-node <a href="https://docs.ray.io/en/latest/tune/tutorials/tune-distributed.html#tune-distributed">distributed hyperparameter sweep</a> in less than 10 lines of code.</li>
<li>Supports any machine learning framework, <a href="https://docs.ray.io/en/latest/tune/tutorials/overview.html#tune-guides">including PyTorch, XGBoost, MXNet, and Keras</a>.</li>
<li>Automatically manages <a href="https://docs.ray.io/en/latest/tune/user-guide.html#tune-checkpoint">checkpoints</a> and logging to <a href="https://docs.ray.io/en/latest/tune/user-guide.html#tune-logging">TensorBoard</a>.</li>
<li>Choose among state of the art algorithms such as <a href="https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#tune-scheduler-pbt">Population Based Training (PBT)</a>, <a href="https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#bayesopt">BayesOptSearch</a>, <a href="https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#tune-scheduler-hyperband">HyperBand/ASHA</a>.</li>
<li>Move your models from training to serving on the same infrastructure with <a href="https://docs.ray.io/en/latest/tune/serve/index.html">Ray Serve</a>.</li>
</ul>
<h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p>首先，需要简单地理解一下Ray.tune中的几个重要概念：</p>
<ul>
<li>Trial：Trial 是一次尝试，它会使用某组配置（例如，一组超参值，或者特定的神经网络架构）来进行训练，并返回该配置下的得分。本质上就是加入了NNIAPI的用户的原始代码。</li>
<li>Experiment：实验是一次寻找模型的最佳超参组合，或最好的神经网络架构的整个过程。 它由Trial和AutoML算法所组成。</li>
<li>Searchspace：搜索空间是模型调优的范围。 例如，超参的取值范围。</li>
<li>Configuration：配置是来自搜索空间的一个参数实例，每个超参都会有一个特定的值。</li>
<li>Tuner: Tuner就是具体的AutoML算法，会为下一个Trial生成新的配置。新的 Trial 会使用这组配置来运行。</li>
<li>Assessor：Assessor分析Trial的中间结果（例如，测试数据集上定期的精度），来确定 Trial 是否应该被提前终止。</li>
<li>Training Platform：训练平台是Trial的执行环境。根据Experiment的配置，可以是本机，远程服务器组，或其它大规模训练平台（例如，Ray自行提供的平台）</li>
</ul>
<p>那么你的实验（Experiment）便是在一定的搜索空间（Searchspace）内寻找最优的一组超参数组合（Configuration），使得该组参数对应的Trail会获得最高的准确率或者得分，在有限的时间和资源限制下，Tuner和Assessor会自动地帮助你更快更好的找到这组参数。</p>
<h2 id="快速入手实例"><a href="#快速入手实例" class="headerlink" title="快速入手实例"></a>快速入手实例</h2><p>为了快速上手，理解Ray.tune的工作流程，不妨训练一个简单的Mnist手写数字识别，网络结构确定后，Ray.tune可以来帮你找到最优的超参。</p>
<h3 id="Pytorch-Model-Setup"><a href="#Pytorch-Model-Setup" class="headerlink" title="Pytorch Model Setup"></a>Pytorch Model Setup</h3><p>首先需要搭建一个能够正常训练的模型，这一部分与Tune本身是无关的。</p>
<p>导入一些依赖项：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> ray <span class="keyword">import</span> tune</span><br><span class="line"><span class="keyword">from</span> ray.tune.schedulers <span class="keyword">import</span> ASHAScheduler</span><br></pre></td></tr></table></figure>
<p>然后使用PyTorch定义一个简单的神经网络模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        super(ConvNet, self).__init__()</span><br><span class="line">        <span class="comment"># In this example, we don&#x27;t change the model architecture</span></span><br><span class="line">        <span class="comment"># due to simplicity.</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">3</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">192</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.relu(F.max_pool2d(self.conv1(x), <span class="number">3</span>))</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">192</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>然后定义具体的训练函数和测试函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Change these values if you want the training to run quicker or slower.</span></span><br><span class="line">EPOCH_SIZE = <span class="number">512</span></span><br><span class="line">TEST_SIZE = <span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">model, optimizer, train_loader</span>):</span></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        <span class="comment"># We set this just for the example to run quickly.</span></span><br><span class="line">        <span class="keyword">if</span> batch_idx * len(data) &gt; EPOCH_SIZE:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = F.nll_loss(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">model, data_loader</span>):</span></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    model.eval()</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> enumerate(data_loader):</span><br><span class="line">            <span class="comment"># We set this just for the example to run quickly.</span></span><br><span class="line">            <span class="keyword">if</span> batch_idx * len(data) &gt; TEST_SIZE:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            data, target = data.to(device), target.to(device)</span><br><span class="line">            outputs = model(data)</span><br><span class="line">            _, predicted = torch.max(outputs.data, <span class="number">1</span>)</span><br><span class="line">            total += target.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == target).sum().item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> correct / total</span><br></pre></td></tr></table></figure>
<h3 id="Setting-up-Tune"><a href="#Setting-up-Tune" class="headerlink" title="Setting up Tune"></a>Setting up Tune</h3><p>现在，需要定义一个可以用于并行训练模型的函数。这个函数将在每一个 <a href="https://docs.ray.io/en/latest/actors.html#actor-guide">Ray Actor (process)</a> 上单独执行。因此，该函数需要将模型的性能传达回Tune主进程中。为此，在训练函数中调用 tune.report，它能够将性能的数值发送回Tune。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_mnist</span>(<span class="params">config</span>):</span></span><br><span class="line">    <span class="comment"># Data Setup</span></span><br><span class="line">    mnist_transforms = transforms.Compose(</span><br><span class="line">        [transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((<span class="number">0.1307</span>, ), (<span class="number">0.3081</span>, ))])</span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(</span><br><span class="line">        datasets.MNIST(<span class="string">&quot;~/data&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=mnist_transforms),</span><br><span class="line">        batch_size=<span class="number">64</span>,</span><br><span class="line">        shuffle=<span class="literal">True</span>)</span><br><span class="line">    test_loader = DataLoader(</span><br><span class="line">        datasets.MNIST(<span class="string">&quot;~/data&quot;</span>, train=<span class="literal">False</span>, transform=mnist_transforms),</span><br><span class="line">        batch_size=<span class="number">64</span>,</span><br><span class="line">        shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = ConvNet()</span><br><span class="line">    optimizer = optim.SGD(</span><br><span class="line">        model.parameters(), lr=config[<span class="string">&quot;lr&quot;</span>], momentum=config[<span class="string">&quot;momentum&quot;</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        train(model, optimizer, train_loader)</span><br><span class="line">        acc = test(model, test_loader)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Send the current training result back to Tune</span></span><br><span class="line">        tune.report(mean_accuracy=acc)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># This saves the model to the trial directory</span></span><br><span class="line">            torch.save(model.state_dict(), <span class="string">&quot;./model.pth&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>为超参建立搜索空间后，调用 tune.run 就可以完成一次Experiment了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">search_space = &#123;</span><br><span class="line">    <span class="string">&quot;lr&quot;</span>: tune.sample_from(<span class="keyword">lambda</span> spec: <span class="number">10</span>**(<span class="number">-10</span> * np.random.rand())),</span><br><span class="line">    <span class="string">&quot;momentum&quot;</span>: tune.uniform(<span class="number">0.1</span>, <span class="number">0.9</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment this to enable distributed execution</span></span><br><span class="line"><span class="comment"># `ray.init(address=&quot;auto&quot;)`</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Download the dataset first</span></span><br><span class="line">datasets.MNIST(<span class="string">&quot;~/data&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">analysis = tune.run(train_mnist, config=search_space)</span><br></pre></td></tr></table></figure>
<p>tune.run 会返回一个Analysis Object。它保存了优化过程的数据，可以绘图进行分析。同时每一个trial的数据自动保存在 ~/ray_results 文件夹中，也可以使用Tesnorboard来分析优化过程。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir ~/ray_results</span><br></pre></td></tr></table></figure>
<p><img src="/2020/11/03/ray1/ray1_tensorboard.png" alt="tensorboard"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Ray</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>Ray.Tune初探（二）：Guide</title>
    <url>/2020/12/03/ray2/</url>
    <content><![CDATA[<h1 id="Tune：使用指南"><a href="#Tune：使用指南" class="headerlink" title="Tune：使用指南"></a>Tune：使用指南</h1><h2 id="资源-Parallelism-GPUs-Distributed"><a href="#资源-Parallelism-GPUs-Distributed" class="headerlink" title="资源 (Parallelism, GPUs, Distributed)"></a>资源 (Parallelism, GPUs, Distributed)</h2><p>Parallelism is determined by <code>resources_per_trial</code> (defaulting to 1 CPU, 0 GPU per trial) and the resources available to Tune (<code>ray.cluster_resources()</code>).</p>
<p>By default, Tune automatically runs N concurrent trials, where N is the number of CPUs (cores) on your machine.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># If you have 4 CPUs on your machine, this will run 4 concurrent trials at a time.</span></span><br><span class="line">tune.run(trainable, num_samples=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>You can override this parallelism with <code>resources_per_trial</code>. Here you can specify your resource requests using either a dictionary or a PlacementGroupFactory object. In any case, Ray Tune will try to start a placement group for each trial.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># If you have 4 CPUs on your machine, this will run 2 concurrent trials at a time.</span></span><br><span class="line">tune.run(trainable, num_samples=<span class="number">10</span>, resources_per_trial=&#123;<span class="string">&quot;cpu&quot;</span>: <span class="number">2</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># If you have 4 CPUs on your machine, this will run 1 trial at a time.</span></span><br><span class="line">tune.run(trainable, num_samples=<span class="number">10</span>, resources_per_trial=&#123;<span class="string">&quot;cpu&quot;</span>: <span class="number">4</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fractional values are also supported, (i.e., &#123;&quot;cpu&quot;: 0.5&#125;).</span></span><br><span class="line">tune.run(trainable, num_samples=<span class="number">10</span>, resources_per_trial=&#123;<span class="string">&quot;cpu&quot;</span>: <span class="number">0.5</span>&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="搜索空间-Grid-Random"><a href="#搜索空间-Grid-Random" class="headerlink" title="搜索空间 (Grid/Random)"></a>搜索空间 (Grid/Random)</h2><h2 id><a href="#" class="headerlink" title=" "></a> </h2>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Ray</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础</title>
    <url>/2022/03/02/ML1/</url>
    <content><![CDATA[<ul>
<li><a href="#偏差与方差">偏差与方差</a><ul>
<li><a href="#导致偏差和方差的原因">导致偏差和方差的原因</a></li>
<li><a href="#深度学习中的偏差与方差">深度学习中的偏差与方差</a></li>
<li><a href="#偏差方差-与-boostingbagging">偏差/方差 与 Boosting/Bagging</a></li>
<li><a href="#偏差与方差的计算公式">偏差与方差的计算公式</a></li>
<li><a href="#偏差与方差的权衡过拟合与模型复杂度的权衡">偏差与方差的权衡（过拟合与模型复杂度的权衡）</a></li>
</ul>
</li>
<li><a href="#生成模型与判别模型">生成模型与判别模型</a></li>
<li><a href="#先验概率与后验概率">先验概率与后验概率</a></li>
</ul>
<!-- /TOC -->
<h2 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h2><blockquote>
<p>《机器学习》 2.5 偏差与方差 - 周志华</p>
<ul>
<li><strong>偏差</strong>与<strong>方差</strong>分别是用于衡量一个模型<strong>泛化误差</strong>的两个方面；<ul>
<li>模型的<strong>偏差</strong>，指的是模型预测的<strong>期望值</strong>与<strong>真实值</strong>之间的差；</li>
<li>模型的<strong>方差</strong>，指的是模型预测的<strong>期望值</strong>与<strong>预测值</strong>之间的差平方和；</li>
</ul>
</li>
<li>在<strong>监督学习</strong>中，模型的<strong>泛化误差</strong>可<strong>分解</strong>为偏差、方差与噪声之和。<div align="center"><img src="/2022/03/02/ML1/TIM截图20180817204652.png" height></div>

</li>
</ul>
</blockquote>
<ul>
<li><strong>偏差</strong>用于描述模型的<strong>拟合能力</strong>；<br><br><strong>方差</strong>用于描述模型的<strong>稳定性</strong>。<div align="center"><img src="/2022/03/02/ML1/TIM截图20180817192259.png" height></div>

</li>
</ul>
<h3 id="导致偏差和方差的原因"><a href="#导致偏差和方差的原因" class="headerlink" title="导致偏差和方差的原因"></a>导致偏差和方差的原因</h3><ul>
<li><strong>偏差</strong>通常是由于我们对学习算法做了<strong>错误的假设</strong>，或者模型的复杂度不够；<ul>
<li>比如真实模型是一个二次函数，而我们假设模型为一次函数，这就会导致偏差的增大（欠拟合）；</li>
<li><strong>由偏差引起的误差</strong>通常在<strong>训练误差</strong>上就能体现，或者说训练误差主要是由偏差造成的</li>
</ul>
</li>
<li><strong>方差</strong>通常是由于<strong>模型的复杂度相对于训练集过高</strong>导致的；<ul>
<li>比如真实模型是一个简单的二次函数，而我们假设模型是一个高次函数，这就会导致方差的增大（过拟合）；</li>
<li><strong>由方差引起的误差</strong>通常体现在测试误差相对训练误差的<strong>增量</strong>上。</li>
</ul>
</li>
</ul>
<h3 id="深度学习中的偏差与方差"><a href="#深度学习中的偏差与方差" class="headerlink" title="深度学习中的偏差与方差"></a>深度学习中的偏差与方差</h3><ul>
<li>神经网络的拟合能力非常强，因此它的<strong>训练误差</strong>（偏差）通常较小；</li>
<li>但是过强的拟合能力会导致较大的方差，使模型的测试误差（<strong>泛化误差</strong>）增大；</li>
<li>因此深度学习的核心工作之一就是研究如何降低模型的泛化误差，这类方法统称为<strong>正则化方法</strong>。<blockquote>
<p>../深度学习/<a href="../A-深度学习/C-专题-正则化">正则化</a></p>
</blockquote>
</li>
</ul>
<h3 id="偏差-方差-与-Boosting-Bagging"><a href="#偏差-方差-与-Boosting-Bagging" class="headerlink" title="偏差/方差 与 Boosting/Bagging"></a>偏差/方差 与 Boosting/Bagging</h3><blockquote>
<p>./集成学习专题/<a href="./C-专题-集成学习#boostingbagging-与-偏差方差-的关系">Boosting/Bagging 与 偏差/方差 的关系</a></p>
</blockquote>
<h3 id="偏差与方差的计算公式"><a href="#偏差与方差的计算公式" class="headerlink" title="偏差与方差的计算公式"></a>偏差与方差的计算公式</h3><ul>
<li><p>记在<strong>训练集 D</strong> 上学得的模型为</p>
<div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=f(\boldsymbol{x};D)"><img src="/2022/03/02/ML1/公式_20180817211749.png" height></a></div>

<p>模型的<strong>期望预测</strong>为</p>
<div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=\large&space;\hat{f}(\boldsymbol{x})=\mathbb{E}_D[f(\boldsymbol{x};D)]"><img src="/2022/03/02/ML1/公式_20180817210758.png" height></a></div>
</li>
<li><p><strong>偏差</strong>（Bias）</p>
<div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=\large&space;bias^2(\boldsymbol{x})=(\hat{f}(\boldsymbol{x})-y)^2"><img src="/2022/03/02/ML1/公式_20180817210106.png" height></a></div>

<blockquote>
<p><strong>偏差</strong>度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力；</p>
</blockquote>
</li>
<li><p><strong>方差</strong>（Variance）</p>
<div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=\large&space;var(\boldsymbol{x})=\mathbb{E}_D\left&space;[&space;\left&space;(&space;f(\boldsymbol{x};D)-\hat{f}(\boldsymbol{x})&space;\right&space;)^2&space;\right&space;]"><img src="/2022/03/02/ML1/公式_20180817211903.png" height></a></div>

<blockquote>
<p><strong>方差</strong>度量了同样大小的<strong>训练集的变动</strong>所导致的学习性能的变化，即刻画了数据扰动所造成的影响（模型的稳定性）；</p>
<!-- - **噪声**
<div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=\large&space;var(\boldsymbol{x})=\mathbb{E}_D\left&space;[&space;\left&space;(&space;f(\boldsymbol{x};D)-\hat{f}(\boldsymbol{x})&space;\right&space;)^2&space;\right&space;]"><img src="ML/公式_20180817212111.png" height="" /></a></div> -->
</blockquote>
</li>
<li><p><strong>噪声</strong>则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。</p>
</li>
<li><p>“<strong>偏差-方差分解</strong>”表明模型的泛化能力是由算法的能力、数据的充分性、任务本身的难度共同决定的。</p>
</li>
</ul>
<h3 id="偏差与方差的权衡（过拟合与模型复杂度的权衡）"><a href="#偏差与方差的权衡（过拟合与模型复杂度的权衡）" class="headerlink" title="偏差与方差的权衡（过拟合与模型复杂度的权衡）"></a>偏差与方差的权衡（过拟合与模型复杂度的权衡）</h3><ul>
<li><p>给定学习任务，</p>
<ul>
<li>当训练不足时，模型的<strong>拟合能力不够</strong>（数据的扰动不足以使模型产生显著的变化），此时<strong>偏差</strong>主导模型的泛化误差；</li>
<li>随着训练的进行，模型的<strong>拟合能力增强</strong>（模型能够学习数据发生的扰动），此时<strong>方差</strong>逐渐主导模型的泛化误差；</li>
<li>当训练充足后，模型的<strong>拟合能力过强</strong>（数据的轻微扰动都会导致模型产生显著的变化），此时即发生<strong>过拟合</strong>（训练数据自身的、非全局的特征也被模型学习了）</li>
</ul>
</li>
<li><p>偏差和方差的关系和<strong>模型容量</strong>（模型复杂度）、<strong>欠拟合</strong>和<strong>过拟合</strong>的概念紧密相联</p>
<div align="center"><img src="/2022/03/02/ML1/TIM截图20180817214034.png" height></div>

<ul>
<li>当模型的容量增大（x 轴）时， 偏差（用点表示）随之减小，而方差（虚线）随之增大</li>
<li>沿着 x 轴存在<strong>最佳容量</strong>，<strong>小于最佳容量会呈现欠拟合</strong>，<strong>大于最佳容量会导致过拟合</strong>。<blockquote>
<p>《深度学习》 5.4.4 权衡偏差和方差以最小化均方误差</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p><strong>Reference</strong></p>
<ul>
<li><a href="http://scott.fortmann-roe.com/docs/BiasVariance.html">Understanding the Bias-Variance Tradeoff</a></li>
<li><a href="https://www.zhihu.com/question/27068705">机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)有什么区别和联系？</a> - 知乎 </li>
</ul>
<h2 id="生成模型与判别模型"><a href="#生成模型与判别模型" class="headerlink" title="生成模型与判别模型"></a>生成模型与判别模型</h2><blockquote>
<p>《统计学习方法》 1.7 生成模型与判别模型</p>
<ul>
<li>监督学习的任务是学习一个模型，对给定的输入预测相应的输出</li>
<li>这个模型的一般形式为一个<strong>决策函数</strong>或一个<strong>条件概率分布</strong>（后验概率）：<div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=\fn_phv&space;\large&space;Y=f(X)\quad&space;\text{or}\quad&space;P(Y|X)"><img src="/2022/03/02/ML1/公式_20180817220004.png" height></a></div>

</li>
</ul>
</blockquote>
<ul>
<li><strong>决策函数</strong>：输入 X 返回 Y；其中 Y 与一个<strong>阈值</strong>比较，然后根据比较结果判定 X 的类别</li>
<li><strong>条件概率分布</strong>：输入 X 返回 <strong>X 属于每个类别的概率</strong>；将其中概率最大的作为 X 所属的类别<ul>
<li>监督学习模型可分为<strong>生成模型</strong>与<strong>判别模型</strong></li>
</ul>
</li>
<li><strong>判别模型</strong>直接学习决策函数或者条件概率分布<ul>
<li>直观来说，<strong>判别模型</strong>学习的是类别之间的最优分隔面，反映的是不同类数据之间的差异</li>
</ul>
</li>
<li><strong>生成模型</strong>学习的是联合概率分布<code>P(X,Y)</code>，然后根据条件概率公式计算 <code>P(Y|X)</code><div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=\fn_phv&space;\large&space;P(Y|X)=\frac{P(X,Y)}{P(X)}"><img src="/2022/03/02/ML1/公式_20180817223923.png" height></a></div>

</li>
</ul>
<p><strong>两者之间的联系</strong></p>
<ul>
<li>由生成模型可以得到判别模型，但由判别模型得不到生成模型。</li>
<li>当存在“<strong>隐变量</strong>”时，只能使用<strong>生成模型</strong><blockquote>
<p>隐变量：当我们找不到引起某一现象的原因时，就把这个在起作用，但无法确定的因素，叫“隐变量”</p>
</blockquote>
</li>
</ul>
<p><strong>优缺点</strong></p>
<ul>
<li><strong>判别模型</strong><ul>
<li>优点<ul>
<li>直接面对预测，往往学习的准确率更高</li>
<li>由于直接学习 <code>P(Y|X)</code> 或 <code>f(X)</code>，可以对数据进行各种程度的抽象，定义特征并使用特征，以简化学习过程</li>
</ul>
</li>
<li>缺点<ul>
<li>不能反映训练数据本身的特性</li>
<li>…</li>
</ul>
</li>
</ul>
</li>
<li><strong>生成模型</strong><ul>
<li>优点<ul>
<li>可以还原出联合概率分布 <code>P(X,Y)</code>，判别方法不能</li>
<li>学习收敛速度更快——即当样本容量增加时，学到的模型可以更快地收敛到真实模型</li>
<li>当存在“隐变量”时，只能使用生成模型</li>
</ul>
</li>
<li>缺点<ul>
<li>学习和计算过程比较复杂</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>常见模型</strong></p>
<ul>
<li>判别模型<ul>
<li>K 近邻、感知机（神经网络）、决策树、逻辑斯蒂回归、<strong>最大熵模型</strong>、SVM、提升方法、<strong>条件随机场</strong></li>
</ul>
</li>
<li>生成模型<ul>
<li>朴素贝叶斯、隐马尔可夫模型、混合高斯模型、贝叶斯网络、马尔可夫随机场</li>
</ul>
</li>
</ul>
<p><strong>Reference</strong></p>
<ul>
<li><a href="https://blog.csdn.net/u012101561/article/details/52814571">机器学习—-生成模型与判别模型</a> - CSDN博客 </li>
<li></li>
</ul>
<h2 id="先验概率与后验概率"><a href="#先验概率与后验概率" class="headerlink" title="先验概率与后验概率"></a>先验概率与后验概率</h2><blockquote>
<p><a href="https://blog.csdn.net/suranxu007/article/details/50326873">先验概率，后验概率，似然概率，条件概率，贝叶斯，最大似然</a> - CSDN博客 </p>
</blockquote>
<p><strong>条件概率</strong>（似然概率）</p>
<ul>
<li>一个事件发生后另一个事件发生的概率。</li>
<li>一般的形式为 <code>P(X|Y)</code>，表示 y 发生的条件下 x 发生的概率。</li>
<li>有时为了区分一般意义上的<strong>条件概率</strong>，也称<strong>似然概率</strong></li>
</ul>
<p><strong>先验概率</strong></p>
<ul>
<li>事件发生前的预判概率</li>
<li>可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。</li>
<li>一般都是<strong>单独事件</strong>发生的概率，如 <code>P(A)</code>、<code>P(B)</code>。</li>
</ul>
<p><strong>后验概率</strong></p>
<ul>
<li>基于先验概率求得的<strong>反向条件概率</strong>，形式上与条件概率相同（若 <code>P(X|Y)</code> 为正向，则 <code>P(Y|X)</code> 为反向）</li>
</ul>
<p><strong>贝叶斯公式</strong><br>  <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=\fn_phv&space;\large&space;P(Y|X)=\frac{P(X|Y)*P(Y)}{P(X)}"><img src="/2022/03/02/ML1/公式_20180817230314.png" height></a></div></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title>个性化推荐系统与强化学习</title>
    <url>/2022/03/03/RLRe/</url>
    <content><![CDATA[<p>通过融合深度学习与知识图谱技术，推荐系统的性能取得了大幅的提升。然而，多数的推荐系统仍是以一步到位的方式建立的：它们有着类似的搭建方式，即在充分获取用户历史数据的前提下，设计并训练特定的监督模型，从而得到用户对于不同物品的喜好程度。这些训练好的模型在部署上线后可以为特定用户识别出最具吸引力的物品，为其做出个性化推荐。在此，人们往往假设用户数据已充分获取，且其行为会在较长时间之内保持稳定，使得上述过程中所建立的推荐模型得以应付实际中的需求。</p>
<p>然而对于诸多现实场景，例如电子商务或者在线新闻平台，用户与推荐系统之间往往会发生持续密切的交互行为。在这一过程中，用户的反馈将弥补可能的数据缺失，同时有力地揭示其当前的行为特征，从而为系统进行更加精准的个性化推荐提供重要的依据。</p>
<p>强化学习为解决这个问题提供了有力支持。依照用户的行为特征，我们将涉及到的推荐场景划分为静态与动态，并分别对其进行讨论。</p>
<h1 id="静态场景下的强化学习"><a href="#静态场景下的强化学习" class="headerlink" title="静态场景下的强化学习"></a>静态场景下的强化学习</h1><p>在静态场景之下，用户的行为特征在与系统的交互过程中保持稳定不变。对于这一场景，一类有代表性的工作是基于上下文多臂老虎机（contextual multi-armed bandit）的推荐系统，它的发展为克服推荐场景中的冷启动问题提供了行之有效的解决方案。</p>
<p>在许多现实应用中，用户的历史行为往往服从特定的长尾分布，即大多数用户仅仅产生规模有限的历史数据，而极少的用户则会生成较为充足的历史数据。这一现象所带来的数据稀疏问题使得传统模型在很多时候难以得到令人满意的实际效果。</p>
<p>为此，一个直接的应对方法是对用户行为进行主动式的探索，即通过对用户发起大量尝试性的推荐，以充分的获得其行为数据，从而保障推荐系统的可用性。然而不幸的是，这一简单的做法势必引发极大的探索开销，使得它在现实中并不具备可行性。</p>
<p>为使主动式探索具备可行的效用开销，人们尝试借助多臂老虎机问题所带来的启发。多臂老虎机问题旨在于“探索-利用”间做出最优的权衡，为此诸多经典算法被相继提出。尽管不同的算法有着不同的实施机制，它们的设计都本着一个共同的原则。</p>
<p>具体说来，系统在做出推荐的时候会综合考虑物品的推荐效用以及累积尝试。较高的推荐效用预示着较低的探索开销，而较低的累积尝试则表明较高的不确定性。为此，不同的算法都会设计特定的整合机制，使得同时具备较高推荐效用与不确定性物品可以得到优先尝试。</p>
<h1 id="动态场景下的强化学习"><a href="#动态场景下的强化学习" class="headerlink" title="动态场景下的强化学习"></a>动态场景下的强化学习</h1><p>在多臂老虎机的设定场景下，用户的实时特征被假设为固定不变的，因此算法并未涉及用户行为发生动态迁移的情况。然而对于诸多现实中的推荐场景，用户行为往往会在交互过程中不断变化。这就要求推荐系统依照用户反馈精确估计其状态发展，并为之制定优化的推荐策略。</p>
<p>具体来讲，一个理想的推荐系统应满足如下双方面的属性。一方面，推荐决策需要充分基于用户过往的反馈数据；另一方面，推荐系统需要优化整个交互过程之中的全局收益。强化学习为实现上述目标提供了有力的技术支持。</p>
<p>在强化学习的框架之下，推荐系统被视作一个智能体（agent），用户当前的行为特征被抽象成为状态（state），待推荐的对象（如候选新闻）则被当作动作（action）。在每次推荐交互中，系统依据用户的状态，选择合适的动作，以最大化特定的长效目标（如点击总数或停留时长）。推荐系统与用户交互过程中所产生的行为数据被组织成为经验（experience），用以记录相应动作产生的奖励（reward）以及状态转移（state-transition）。基于不断积累的经验，强化学习算法得出策略（policy），用以指导特定状态下最优的动作选取。   </p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode 日记：日常练习篇</title>
    <url>/2022/03/01/Leetcode2/</url>
    <content><![CDATA[<h1 id="179-最大数"><a href="#179-最大数" class="headerlink" title="179. 最大数"></a>179. 最大数</h1><h2 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h2><p>给定一组非负整数 nums，重新排列每个数的顺序（每个数不可拆分）使之组成一个最大的整数。</p>
<p>注意：输出结果可能非常大，所以你需要返回一个字符串而不是整数。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">bool</span> <span class="title">cmp</span> <span class="params">(<span class="keyword">int</span> &amp;a, <span class="keyword">int</span> &amp;b)</span></span>&#123;</span><br><span class="line">            <span class="built_in">string</span> aa = to_string(a) + to_string(b);</span><br><span class="line">            <span class="built_in">string</span> bb = to_string(b) + to_string(a);</span><br><span class="line">            <span class="keyword">return</span> aa &gt; bb;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">largestNumber</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">string</span> ans;</span><br><span class="line">        sort(nums.begin(), nums.end(), cmp);</span><br><span class="line">        <span class="keyword">if</span>(nums[<span class="number">0</span>] == <span class="number">0</span>) <span class="keyword">return</span> <span class="string">&quot;0&quot;</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">auto</span> &amp;n : nums)&#123;</span><br><span class="line">            ans += to_string(n);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="769-最多能完成排序的块"><a href="#769-最多能完成排序的块" class="headerlink" title="769. 最多能完成排序的块"></a>769. 最多能完成排序的块</h1><h2 id="题目描述：-1"><a href="#题目描述：-1" class="headerlink" title="题目描述："></a>题目描述：</h2><p>给定一个长度为 n 的整数数组 arr ，它表示在 [0, n - 1] 范围内的整数的排列。</p>
<p>我们将 arr 分割成若干 块 (即分区)，并对每个块单独排序。将它们连接起来后，使得连接的结果和按升序排序后的原数组相同。</p>
<p>返回数组能分成的最多块数量。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxChunksToSorted</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; arr)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = arr.size();</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>, max_value = arr[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line">            max_value = max(arr[i], max_value);</span><br><span class="line">            <span class="keyword">if</span>(max_value == i)&#123;</span><br><span class="line">                ++res;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="739-每日温度"><a href="#739-每日温度" class="headerlink" title="739. 每日温度"></a>739. 每日温度</h1><h2 id="题目描述：-2"><a href="#题目描述：-2" class="headerlink" title="题目描述："></a>题目描述：</h2><p>给定一个整数数组 temperatures ，表示每天的温度，返回一个数组 answer ，其中 answer[i] 是指在第 i 天之后，才会有更高的温度。如果气温在这之后都不会升高，请在该位置用 0 来代替。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">dailyTemperatures</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; temperatures)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = temperatures.size();</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">1</span>)  <span class="keyword">return</span> &#123;<span class="number">0</span>&#125;;</span><br><span class="line">        <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; ss;</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">res</span><span class="params">(n)</span></span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line">            <span class="keyword">while</span>(!ss.empty())&#123;</span><br><span class="line">                <span class="keyword">int</span> pre_index = ss.top();</span><br><span class="line">                <span class="keyword">if</span>(temperatures[i] &lt;= temperatures[pre_index])&#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                ss.pop();</span><br><span class="line">                res[pre_index] = i - pre_index;</span><br><span class="line">            &#125;</span><br><span class="line">            ss.push(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="218-天际线问题"><a href="#218-天际线问题" class="headerlink" title="218. 天际线问题"></a>218. 天际线问题</h1><p>城市的 天际线 是从远处观看该城市中所有建筑物形成的轮廓的外部轮廓。给你所有建筑物的位置和高度，请返回 由这些建筑物形成的 天际线 。</p>
<p>每个建筑物的几何信息由数组 buildings 表示，其中三元组 buildings[i] = [lefti, righti, heighti] 表示：</p>
<p>lefti 是第 i 座建筑物左边缘的 x 坐标。<br>righti 是第 i 座建筑物右边缘的 x 坐标。<br>heighti 是第 i 座建筑物的高度。<br>你可以假设所有的建筑都是完美的长方形，在高度为 0 的绝对平坦的表面上。</p>
<p>天际线 应该表示为由 “关键点” 组成的列表，格式 [[x1,y1],[x2,y2],…] ，并按 x 坐标 进行 排序 。关键点是水平线段的左端点。列表中最后一个点是最右侧建筑物的终点，y 坐标始终为 0 ，仅用于标记天际线的终点。此外，任何两个相邻建筑物之间的地面都应被视为天际线轮廓的一部分。</p>
<p>注意：输出天际线中不得有连续的相同高度的水平线。例如 […[2 3], [4 5], [7 5], [11 5], [12 7]…] 是不正确的答案；三条高度为 5 的线应该在最终输出中合并为一个：[…[2 3], [4 5], [12 7], …]</p>
<p>1.判断高度最高的矩阵和当前矩阵是否重合，最高矩阵的右端点大于等于当前矩阵的左端点那么两个矩阵有重合。<br>2.使用优先级队列存储矩阵高度，当矩阵重合时，方便选择端点的最高高度<br>3.处理左端点，将当前矩阵的高度入队，选择左端点和最高高度组成左天际线<br>4.处理右端点，选择最高高度的矩阵的右端点，及其右侧的重合的矩阵（不包括本矩阵）最高高度，组成右天际线</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; <span class="title">getSkyline</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; buildings)</span> </span>&#123;</span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; ans;</span><br><span class="line"><span class="built_in">priority_queue</span>&lt;<span class="built_in">pair</span>&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&gt; max_heap; </span><br><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>, len = buildings.size();</span><br><span class="line"><span class="keyword">int</span> cur_x, cur_h;</span><br><span class="line"><span class="keyword">while</span> (i &lt; len || !max_heap.empty()) &#123;</span><br><span class="line">    <span class="comment">//如果最高的矩阵和当前矩阵重合，处理左端点</span></span><br><span class="line">    <span class="keyword">if</span> (max_heap.empty() || i &lt; len &amp;&amp; buildings[i][<span class="number">0</span>] &lt;= max_heap.top().second) &#123;</span><br><span class="line">        cur_x = buildings[i][<span class="number">0</span>];</span><br><span class="line">        <span class="comment">//相同的左端点全部入队，选择最高高度</span></span><br><span class="line">        <span class="keyword">while</span> (i &lt; len &amp;&amp; cur_x == buildings[i][<span class="number">0</span>]) &#123;</span><br><span class="line">            max_heap.emplace(buildings[i][<span class="number">2</span>], buildings[i][<span class="number">1</span>]);</span><br><span class="line">            <span class="comment">//遍历矩阵</span></span><br><span class="line">            ++i;</span><br><span class="line">        &#125; </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//如果最高的矩阵和当前矩阵不重合，处理之前重合矩阵的右端点</span></span><br><span class="line">        cur_x = max_heap.top().second;</span><br><span class="line">        <span class="comment">//选择其右侧重合的矩阵（不包括本矩阵）最高高度</span></span><br><span class="line">        <span class="keyword">while</span> (!max_heap.empty() &amp;&amp; cur_x &gt;= max_heap.top().second) &#123;</span><br><span class="line">            max_heap.pop();</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">    cur_h = (max_heap.empty()) ? <span class="number">0</span> : max_heap.top().first;</span><br><span class="line">    <span class="keyword">if</span> (ans.empty() || cur_h != ans.back()[<span class="number">1</span>]) &#123;</span><br><span class="line">        ans.push_back(&#123;cur_x, cur_h&#125;);</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="303-区域和检索-数组不可变"><a href="#303-区域和检索-数组不可变" class="headerlink" title="303. 区域和检索 - 数组不可变"></a>303. 区域和检索 - 数组不可变</h1><p>给定一个整数数组  nums，处理以下类型的多个查询:</p>
<p>计算索引 left 和 right （包含 left 和 right）之间的 nums 元素的 和 ，其中 left &lt;= right<br>实现 NumArray 类：</p>
<p>NumArray(int[] nums) 使用数组 nums 初始化对象<br>int sumRange(int i, int j) 返回数组 nums 中索引 left 和 right 之间的元素的 总和 ，包含 left 和 right 两点（也就是 nums[left] + nums[left + 1] + … + nums[right] )</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NumArray</span> &#123;</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; psum;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    NumArray(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums): psum(nums.size() + <span class="number">1</span>, <span class="number">0</span>) &#123;</span><br><span class="line">        partial_sum(nums.begin(), nums.end(), psum.begin() + <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">sumRange</span><span class="params">(<span class="keyword">int</span> left, <span class="keyword">int</span> right)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> psum[right+<span class="number">1</span>] - psum[left];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="210-课程表-II"><a href="#210-课程表-II" class="headerlink" title="210. 课程表 II"></a>210. 课程表 II</h1><p>现在你总共有 numCourses 门课需要选，记为 0 到 numCourses - 1。给你一个数组 prerequisites ，其中 prerequisites[i] = [ai, bi] ，表示在选修课程 ai 前 必须 先选修 bi 。</p>
<p>例如，想要学习课程 0 ，你需要先完成课程 1 ，我们用一个匹配来表示：[0,1] 。<br>返回你为了学完所有课程所安排的学习顺序。可能会有多个正确的顺序，你只要返回 任意一种 就可以了。如果不可能完成所有课程，返回 一个空数组 。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">findOrder</span><span class="params">(<span class="keyword">int</span> numCourses, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; prerequisites)</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; <span class="title">graph</span><span class="params">(numCourses, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;())</span></span>;</span><br><span class="line">        vector&lt;int&gt; indegree(numCourses, 0), res;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">const</span> <span class="keyword">auto</span> &amp; prerequisite: prerequisites)&#123;</span><br><span class="line">            graph[prerequisite[<span class="number">1</span>]].push_back(prerequisite[<span class="number">0</span>]);</span><br><span class="line">            ++indegree[prerequisite[<span class="number">0</span>]];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; q;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; indegree.size(); ++i)&#123;</span><br><span class="line">            <span class="keyword">if</span>(!indegree[i])&#123;</span><br><span class="line">                q.push(i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(!q.empty())&#123;</span><br><span class="line">            <span class="keyword">int</span> u = q.front();</span><br><span class="line">            res.push_back(u);</span><br><span class="line">            q.pop();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">auto</span> v: graph[u])&#123;</span><br><span class="line">                --indegree[v];</span><br><span class="line">                <span class="keyword">if</span>(!indegree[v])&#123;</span><br><span class="line">                    q.push(v);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; indegree.size(); ++i)&#123;</span><br><span class="line">            <span class="keyword">if</span>(indegree[i])</span><br><span class="line">                <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>题</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础(二)</title>
    <url>/2022/03/07/ML2/</url>
    <content><![CDATA[<h2 id="RoadMap"><a href="#RoadMap" class="headerlink" title="RoadMap"></a><strong>RoadMap</strong></h2><ul>
<li><a href="#逻辑斯蒂回归">逻辑斯蒂回归</a></li>
<li><a href="#支持向量机">支持向量机</a></li>
<li><a href="#决策树">决策树</a></li>
<li><a href="#adaboost-算法">AdaBoost 算法</a><ul>
<li><a href="#梯度提升决策树-gbdt">梯度提升决策树 GBDT</a></li>
</ul>
</li>
<li><a href="#机器学习实践">机器学习实践</a></li>
</ul>
<h2 id="Index"><a href="#Index" class="headerlink" title="Index"></a><strong>Index</strong></h2><!-- TOC -->
<ul>
<li><a href="#符号说明">符号说明</a></li>
<li><a href="#信息论">信息论</a></li>
<li><a href="#逻辑斯蒂回归">逻辑斯蒂回归</a><ul>
<li><a href="#逻辑斯蒂回归模型定义">逻辑斯蒂回归模型定义</a></li>
<li><a href="#逻辑斯蒂回归推导">逻辑斯蒂回归推导</a></li>
<li><a href="#多分类逻辑斯蒂回归模型-todo">多分类逻辑斯蒂回归模型 TODO</a></li>
</ul>
</li>
<li><a href="#支持向量机">支持向量机</a><ul>
<li><a href="#支持向量机简述">支持向量机简述</a><ul>
<li><a href="#什么是支持向量">什么是支持向量</a></li>
<li><a href="#支持向量机的分类">支持向量机的分类</a></li>
<li><a href="#核函数与核技巧">核函数与核技巧</a></li>
<li><a href="#最大间隔超平面背后的原理">最大间隔超平面背后的原理</a></li>
</ul>
</li>
<li><a href="#支持向量机推导">支持向量机推导</a><ul>
<li><a href="#线性可分支持向量机推导">线性可分支持向量机推导</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#决策树">决策树</a><ul>
<li><a href="#信息增益与信息增益比-todo">信息增益与信息增益比 TODO</a></li>
<li><a href="#分类树---id3-决策树与-c45-决策树-todo">分类树 - ID3 决策树与 C4.5 决策树 TODO</a></li>
<li><a href="#决策树如何避免过拟合-todo">决策树如何避免过拟合 TODO</a></li>
<li><a href="#回归树---cart-决策树">回归树 - CART 决策树</a><ul>
<li><a href="#cart-回归树算法推导">CART 回归树算法推导</a></li>
<li><a href="#示例-选择切分变量与切分点">示例: 选择切分变量与切分点</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#集成学习">集成学习</a><ul>
<li><a href="#集成学习的基本策略3">集成学习的基本策略(3)</a><ul>
<li><a href="#1-boosting">1. Boosting</a><ul>
<li><a href="#boosting-策略要解决的两个基本问题">Boosting 策略要解决的两个基本问题</a></li>
</ul>
</li>
<li><a href="#2-bagging">2. Bagging</a></li>
<li><a href="#3-stacking">3. Stacking</a></li>
</ul>
</li>
<li><a href="#adaboost-算法">AdaBoost 算法</a><ul>
<li><a href="#adaboost-算法描述">AdaBoost 算法描述</a></li>
<li><a href="#adaboost-算法要点说明">AdaBoost 算法要点说明</a></li>
</ul>
</li>
<li><a href="#前向分步算法">前向分步算法</a><ul>
<li><a href="#加法模型">加法模型</a></li>
<li><a href="#前向分步算法描述">前向分步算法描述</a></li>
<li><a href="#前向分步算法与-adaboost">前向分步算法与 AdaBoost</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#梯度提升决策树-gbdt">梯度提升决策树 GBDT</a><ul>
<li><a href="#提升树-boosting-tree">提升树 Boosting Tree</a><ul>
<li><a href="#提升树算法描述">提升树算法描述</a></li>
</ul>
</li>
<li><a href="#梯度提升gb算法">梯度提升(GB)算法</a></li>
<li><a href="#gbdt-算法描述">GBDT 算法描述</a></li>
<li><a href="#xgboost-算法">XGBoost 算法</a><ul>
<li><a href="#xgboost-与-gb-的主要区别">XGBoost 与 GB 的主要区别</a></li>
<li><a href="#xgboost-的一些内部优化">XGBoost 的一些内部优化</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#随机森林">随机森林</a></li>
<li><a href="#机器学习实践">机器学习实践</a><ul>
<li><a href="#boxmuller-变换">Box–Muller 变换</a></li>
</ul>
</li>
<li><a href="#降维">降维</a><ul>
<li><a href="#svd">SVD</a></li>
<li><a href="#pca">PCA</a></li>
<li><a href="#t-sne">t-SNE</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- /TOC -->
<!-- # 什么是推导
- 给出一个问题或模型的定义，然后求其最优解的过程 -->
<h1 id="符号说明"><a href="#符号说明" class="headerlink" title="符号说明"></a>符号说明</h1><ul>
<li>基本遵从《统计学习方法》一书中的符号表示。</li>
<li><p>除特别说明，默认<code>w</code>为行向量，<code>x</code>为列向量，以避免在<code>wx</code>中使用转置符号；但有些公式为了更清晰区分向量与标量，依然会使用<code>^T</code>的上标，注意区分。</p>
<p>  输入实例<code>x</code>的特征向量记为：</p>
  <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=x=(x^{(1)},x^{(2)},\cdots,x^{(n)})^T"><img src="/2022/03/07/ML2/_assets/公式_20180713114026.png" height></a></div>

<p>  注意：<code>x_i</code> 和 <code>x^(i)</code> 含义不同，前者表示训练集中第 i 个实例，后者表示特征向量中的第 i 个分量；因此，通常记训练集为：</p>
  <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=T=\left&space;\{&space;(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)&space;\right&space;\}"><img src="/2022/03/07/ML2/_assets/公式_20180713132400.png" height></a></div>

<blockquote>
<p>特征向量用小<code>n</code>表示维数，训练集用大<code>N</code>表示个数</p>
</blockquote>
</li>
<li><p><strong>公式说明</strong></p>
<p>  所有公式都可以<strong>点击</strong>跳转至编辑页面，但是部分公式符号会与超链接中的转义冲突；如果编辑页面的公式与本页面中的不同，可以打开源文件，通过原链接打开。</p>
</li>
</ul>
<h1 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h1><blockquote>
<p>《深度学习》 3.13 信息论</p>
<ul>
<li>信息论的基本想法是：一件不太可能的事发生，要比一件非常可能的事发生，提供更多的信息。</li>
<li>该想法可描述为以下性质：<ol>
<li>非常可能发生的事件信息量要比较少，并且极端情况下，一定能够发生的事件应该没有信息量。</li>
<li>比较不可能发生的事件具有更大的信息量。</li>
<li>独立事件应具有增量的信息。例如，投掷的硬币两次正面朝上传递的信息量，应该是投掷一次硬币正面朝上的信息量的两倍。</li>
</ol>
</li>
</ul>
</blockquote>
<h3>信息熵 与 自信息</h3>

<ul>
<li><p><strong>自信息</strong>（self-information）是一种量化以上性质的函数，定义一个事件<code>x</code>的自信息为：</p>
  <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=I(x)=-\log&space;P(x)"><img src="/2022/03/07/ML2/_assets/公式_20180610215339.png" height></a></div>

<blockquote>
<p>当该对数的底数为自然对数 e 时，单位为奈特（nats）；当以 2 为底数时，单位为比特（bit）或香农（shannons）</p>
</blockquote>
</li>
<li><p>自信息只处理单个的输出。</p>
</li>
<li><p><strong>信息熵</strong>（Information-entropy）用于对整个概率分布中的<strong>不确定性总量</strong>进行量化：</p>
  <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=H(\mathrm{X})=\mathbb{E}_{\mathrm{X}&space;\sim&space;P}[I(x)]=-\sum_{x&space;\in&space;\mathrm{X}}P(x)\log&space;P(x)"><img src="/2022/03/07/ML2/_assets/公式_20180610215417.png" height></a></div>

<blockquote>
<p>信息论中，记 <code>0log0 = 0</code></p>
</blockquote>
</li>
</ul>
<h3>交叉熵 与 相对熵/KL散度</h3>

<ul>
<li><p>定义 <strong>P 对 Q</strong> 的 <strong>KL 散度</strong>（Kullback-Leibler divergence）：</p>
  <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=D_P(Q)=\mathbb{E}_{\mathrm{X}\sim&space;P}\left&space;[&space;\log&space;\frac{P(x)}{Q(x)}&space;\right&space;]=\sum_{x&space;\in&space;\mathrm{X}}P(x)\left&space;[&space;\log&space;P(x)-\log&space;Q(x)&space;\right&space;]"><img src="/2022/03/07/ML2/_assets/公式_20180610215445.png" height></a></div>

</li>
</ul>
<p><strong>KL 散度在信息论中度量的是哪个直观量？</strong></p>
<ul>
<li>在离散型变量的情况下， KL 散度衡量的是：当我们使用一种被设计成能够使得概率分布 Q 产生的消息的长度最小的编码，发送包含由概率分布 P 产生的符号的消息时，所需要的额外信息量。</li>
</ul>
<p><strong>KL散度的性质</strong>：</p>
<ul>
<li>非负；KL 散度为 0 当且仅当P 和 Q 在离散型变量的情况下是相同的分布，或者在连续型变量的情况下是“几乎处处”相同的</li>
<li>不对称；D_p(q) != D_q(p)</li>
</ul>
<p><strong>交叉熵</strong>（cross-entropy）：</p>
<div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=H_P(Q)=-\mathbb{E}_{\mathrm{X}\sim&space;P}\log&space;Q(x)=-\sum_{x&space;\in&space;\mathrm{X}}P(x)\log&space;Q(x)"><img src="/2022/03/07/ML2/_assets/公式_20180610215522.png" height></a></div>

<blockquote>
<p><a href="https://blog.csdn.net/haolexiao/article/details/70142571">信息量，信息熵，交叉熵，KL散度和互信息（信息增益）</a> - CSDN博客</p>
</blockquote>
<p><strong>交叉熵 与 KL 散度的关系</strong></p>
<ul>
<li><p><strong>针对 Q 最小化交叉熵等价于最小化 P 对 Q 的 KL 散度</strong>，因为 Q 并不参与被省略的那一项。</p>
  <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=H_P(Q)=H(P)&plus;D_P(Q)"><img src="/2022/03/07/ML2/_assets/公式_20180610215554.png" height></a></div>
</li>
<li><p>最大似然估计中，最小化 KL 散度其实就是在最小化分布之间的交叉熵。</p>
<blockquote>
<p>《深度学习》 ch5.5 - 最大似然估计</p>
</blockquote>
</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Ray：Data</title>
    <url>/2022/04/07/ray_data/</url>
    <content><![CDATA[<h1 id="Ray数据集-分布式数据加载和计算"><a href="#Ray数据集-分布式数据加载和计算" class="headerlink" title="Ray数据集:分布式数据加载和计算"></a>Ray数据集:分布式数据加载和计算</h1><p>Ray数据集是在Ray库和应用程序中加载和交换数据的标准方式。它们提供基本的分布式数据转换，如<code>映射</code>、<code>过滤</code>和<code>重分区</code>，并与各种文件格式、数据源和分布式框架兼容。</p>
<p>Ray数据集简化了通用GPU和CPU并行计算;例如，GPU批处理推理。在这种尴尬的并行计算情况下，它为Ray任务和角色提供了更高层次的API，内部处理批处理、流水线和内存管理等操作。</p>
<p><img src="/2022/04/07/ray_data/dataset.svg" alt="Ray_data_head"></p>
<p>作为Ray生态系统的一部分，Ray数据集可以充分利用Ray的分布式调度器的全部功能，例如，使用actor来优化设置时间和GPU调度。</p>
<h1 id="数据集快速启动"><a href="#数据集快速启动" class="headerlink" title="数据集快速启动"></a>数据集快速启动</h1><p>Ray数据集实现分布式 <a href="https://arrow.apache.org/">Arrow</a>。数据集由Ray对象引用<em>blocks</em>的列表组成。每个<em>block</em>包含<a href="https://arrow.apache.org/docs/python/data.html#tables">Arrow table</a>(创建或转换为表格或张量数据时)、<a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Pandas DataFrame</a>(创建或转换为Pandas数据时)或Python列表(否则)中的一组项。让我们从创建数据集开始。</p>
<h1 id="创建数据集"><a href="#创建数据集" class="headerlink" title="创建数据集"></a>创建数据集</h1><p>运行<code>pip install &quot;ray[data]&quot;</code>开始!</p>
<p>可以从使用<code>ray.data.range()</code>和<code>ray.data.from_items()</code>从合成数据创建数据集开始。数据集既可以保存普通的Python对象(即它们的模式是Python类型)，也可以保存Arrow记录(在这种情况下它们的模式是Arrow)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a Dataset of Python objects.</span></span><br><span class="line">ds = ray.data.range(<span class="number">10000</span>)</span><br><span class="line"><span class="comment"># -&gt; Dataset(num_blocks=200, num_rows=10000, schema=&lt;class &#x27;int&#x27;&gt;)</span></span><br><span class="line"></span><br><span class="line">ds.take(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># -&gt; [0, 1, 2, 3, 4]</span></span><br><span class="line"></span><br><span class="line">ds.count()</span><br><span class="line"><span class="comment"># -&gt; 10000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a Dataset of Arrow records.</span></span><br><span class="line">ds = ray.data.from_items([&#123;<span class="string">&quot;col1&quot;</span>: i, <span class="string">&quot;col2&quot;</span>: str(i)&#125; <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>)])</span><br><span class="line"><span class="comment"># -&gt; Dataset(num_blocks=200, num_rows=10000, schema=&#123;col1: int64, col2: string&#125;)</span></span><br><span class="line"></span><br><span class="line">ds.show(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># -&gt; &#123;&#x27;col1&#x27;: 0, &#x27;col2&#x27;: &#x27;0&#x27;&#125;</span></span><br><span class="line"><span class="comment"># -&gt; &#123;&#x27;col1&#x27;: 1, &#x27;col2&#x27;: &#x27;1&#x27;&#125;</span></span><br><span class="line"><span class="comment"># -&gt; &#123;&#x27;col1&#x27;: 2, &#x27;col2&#x27;: &#x27;2&#x27;&#125;</span></span><br><span class="line"><span class="comment"># -&gt; &#123;&#x27;col1&#x27;: 3, &#x27;col2&#x27;: &#x27;3&#x27;&#125;</span></span><br><span class="line"><span class="comment"># -&gt; &#123;&#x27;col1&#x27;: 4, &#x27;col2&#x27;: &#x27;4&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line">ds.schema()</span><br><span class="line"><span class="comment"># -&gt; col1: int64</span></span><br><span class="line"><span class="comment"># -&gt; col2: string</span></span><br></pre></td></tr></table></figure>
<p>数据集可以从本地磁盘或远程数据源(如S3)上的文件创建。pyarrow支持的任何文件系统都可以用来指定文件位置:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Read a directory of files in remote storage.</span></span><br><span class="line">ds = ray.data.read_csv(<span class="string">&quot;s3://bucket/path&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read multiple local files.</span></span><br><span class="line">ds = ray.data.read_csv([<span class="string">&quot;/path/to/file1&quot;</span>, <span class="string">&quot;/path/to/file2&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read multiple directories.</span></span><br><span class="line">ds = ray.data.read_csv([<span class="string">&quot;s3://bucket/path1&quot;</span>, <span class="string">&quot;s3://bucket/path2&quot;</span>])</span><br></pre></td></tr></table></figure>
<p>最后，你可以从Ray对象存储或兼容Ray的分布式DataFrames中创建一个数据集:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> dask.dataframe <span class="keyword">as</span> dd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a Dataset from a list of Pandas DataFrame objects.</span></span><br><span class="line">pdf = pd.DataFrame(&#123;<span class="string">&quot;one&quot;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&quot;two&quot;</span>: [<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>]&#125;)</span><br><span class="line">ds = ray.data.from_pandas([pdf])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a Dataset from a Dask-on-Ray DataFrame.</span></span><br><span class="line">dask_df = dd.from_pandas(pdf, npartitions=<span class="number">10</span>)</span><br><span class="line">ds = ray.data.from_dask(dask_df)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="保存数据集"><a href="#保存数据集" class="headerlink" title="保存数据集"></a>保存数据集</h1><p>数据集可以使用<code>.write_csv()</code>、<code>.write_json()</code>和<code>.write_parquet()</code>写入本地或远程存储。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Write to csv files in /tmp/output.</span></span><br><span class="line">ray.data.range(<span class="number">10000</span>).write_csv(<span class="string">&quot;/tmp/output&quot;</span>)</span><br><span class="line"><span class="comment"># -&gt; /tmp/output/data0.csv, /tmp/output/data1.csv, ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use repartition to control the number of output files:</span></span><br><span class="line">ray.data.range(<span class="number">10000</span>).repartition(<span class="number">1</span>).write_csv(<span class="string">&quot;/tmp/output2&quot;</span>)</span><br><span class="line"><span class="comment"># -&gt; /tmp/output2/data0.csv</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Transforming-Datasets"><a href="#Transforming-Datasets" class="headerlink" title="Transforming Datasets"></a>Transforming Datasets</h1><p>数据集可以使用<code>.map_batches()</code>进行并行转换。Ray将使用给定的函数转换数据集中的记录批。函数必须返回一批记录。允许您筛选或向批处理中添加其他记录，这将改变数据集的大小。<br>转换被急切地执行并阻塞，直到操作完成。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform_batch</span>(<span class="params">df: pandas.DataFrame</span>) -&gt; pandas.DataFrame:</span></span><br><span class="line">    <span class="keyword">return</span> df.applymap(<span class="keyword">lambda</span> x: x * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">ds = ray.data.range_arrow(<span class="number">10000</span>)</span><br><span class="line">ds = ds.map_batches(transform_batch, batch_format=<span class="string">&quot;pandas&quot;</span>)</span><br><span class="line"><span class="comment"># -&gt; Map Progress: 100%|████████████████████| 200/200 [00:00&lt;00:00, 1927.62it/s]</span></span><br><span class="line">ds.take(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># -&gt; [&#123;&#x27;value&#x27;: 0&#125;, &#123;&#x27;value&#x27;: 2&#125;, ...]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>批处理格式可以使用batch_format选项指定，默认值为” native “，这意味着支持arrow的批处理使用pandas格式，其他类型使用Python列表。您还可以显式地指定“arrow”或“pandas”来强制转换为该批格式。批量大小也可以选择。如果没有给出，批处理大小将默认为整个块。</p>
<p>数据集还提供了方便的方法map、flat_map和filter，它们不是向量化的(比map_batches慢)，但可能对开发有用。</p>
<p>默认情况下，使用Ray任务执行转换。对于需要设置的转换，指定<code>compute=ray.data.ActorPoolStrategy(min, max)</code>和Ray将使用一个由min到max的角色自动伸缩的角色池来执行你的转换。对于固定大小的actor池，指定<code>ActorPoolStrategy(n, n)</code>。下面是一个使用Ray Data读取、转换和保存批处理推理结果的端到端示例:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> ray.data <span class="keyword">import</span> ActorPoolStrategy</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example of GPU batch inference on an ImageNet model.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">images: List[bytes]</span>) -&gt; List[bytes]:</span></span><br><span class="line">    <span class="keyword">return</span> images</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BatchInferModel</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.model = ImageNetModel()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, batch: pd.DataFrame</span>) -&gt; pd.DataFrame:</span></span><br><span class="line">        <span class="keyword">return</span> self.model(batch)</span><br><span class="line"></span><br><span class="line">ds = ray.data.read_binary_files(<span class="string">&quot;s3://bucket/image-dir&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocess the data.</span></span><br><span class="line">ds = ds.map_batches(preprocess)</span><br><span class="line"><span class="comment"># -&gt; Map Progress: 100%|████████████████████| 200/200 [00:00&lt;00:00, 1123.54it/s]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply GPU batch inference with actors, and assign each actor a GPU using</span></span><br><span class="line"><span class="comment"># ``num_gpus=1`` (any Ray remote decorator argument can be used here).</span></span><br><span class="line">ds = ds.map_batches(</span><br><span class="line">    BatchInferModel, compute=ActorPoolStrategy(<span class="number">10</span>, <span class="number">20</span>),</span><br><span class="line">    batch_size=<span class="number">256</span>, num_gpus=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># -&gt; Map Progress (16 actors 4 pending): 100%|██████| 200/200 [00:07, 27.60it/s]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the results.</span></span><br><span class="line">ds.repartition(<span class="number">1</span>).write_json(<span class="string">&quot;s3://bucket/inference-results&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="传递和访问数据集"><a href="#传递和访问数据集" class="headerlink" title="传递和访问数据集"></a>传递和访问数据集</h1><p>数据集可以传递给Ray任务或角色，并通过.iter_batches()或.iter_rows()访问。这不会导致复制，因为数据集的块是作为Ray对象引用传递的:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">consume</span>(<span class="params">data: Dataset[int]</span>) -&gt; int:</span></span><br><span class="line">    num_batches = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> data.iter_batches():</span><br><span class="line">        num_batches += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> num_batches</span><br><span class="line"></span><br><span class="line">ds = ray.data.range(<span class="number">10000</span>)</span><br><span class="line">ray.get(consume.remote(ds))</span><br><span class="line"><span class="comment"># -&gt; 200</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>数据集可以被分割成不相交的子数据集。如果您向split()函数传递一个actor句柄列表以及所需的分割数量，那么支持位置感知的分割。这是一个常见的模式，用于在分布式训练参与者之间加载和分割数据:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ray.remote(num_gpus=1)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Worker</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, rank: int</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self, shard: ray.data.Dataset[int]</span>) -&gt; int:</span></span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> shard.iter_batches(batch_size=<span class="number">256</span>):</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> shard.count()</span><br><span class="line"></span><br><span class="line">workers = [Worker.remote(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">16</span>)]</span><br><span class="line"><span class="comment"># -&gt; [Actor(Worker, ...), Actor(Worker, ...), ...]</span></span><br><span class="line"></span><br><span class="line">ds = ray.data.range(<span class="number">10000</span>)</span><br><span class="line"><span class="comment"># -&gt; Dataset(num_blocks=200, num_rows=10000, schema=&lt;class &#x27;int&#x27;&gt;)</span></span><br><span class="line"></span><br><span class="line">shards = ds.split(n=<span class="number">16</span>, locality_hints=workers)</span><br><span class="line"><span class="comment"># -&gt; [Dataset(num_blocks=13, num_rows=650, schema=&lt;class &#x27;int&#x27;&gt;),</span></span><br><span class="line"><span class="comment">#     Dataset(num_blocks=13, num_rows=650, schema=&lt;class &#x27;int&#x27;&gt;), ...]</span></span><br><span class="line"></span><br><span class="line">ray.get([w.train.remote(s) <span class="keyword">for</span> w, s <span class="keyword">in</span> zip(workers, shards)])</span><br><span class="line"><span class="comment"># -&gt; [650, 650, ...]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Ray</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>Ray：Core</title>
    <url>/2022/04/09/ray_core/</url>
    <content><![CDATA[<h1 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h1><p>本节概述Ray的关键概念。这些原语一起工作，使Ray能够灵活地支持广泛的分布式应用程序。</p>
<h2 id="任务Tasks"><a href="#任务Tasks" class="headerlink" title="任务Tasks"></a>任务Tasks</h2><p>Ray允许任意函数在不同的Python工作器上异步执行。这些异步Ray函数被称为“Tasks”。Ray使Task能够根据cpu、gpu和自定义资源来指定它们的资源需求。集群调度器使用这些资源请求来跨集群分发任务以实现并行执行。</p>
<h2 id="演员Actors"><a href="#演员Actors" class="headerlink" title="演员Actors"></a>演员Actors</h2><p>Actors将Ray API从函数(任务)扩展到类。参与者本质上是一个有状态的worker(或server)。当一个新的actor被实例化时，一个新的worker被创建，并且actor的方法被安排在那个特定的worker上，并且可以访问和改变那个worker的状态。和Task一样，Actor也支持CPU、GPU和自定义资源需求。</p>
<h2 id="对象Object"><a href="#对象Object" class="headerlink" title="对象Object"></a>对象Object</h2><p>在Ray中，Task和Actor创建和计算Object。我们将这些Object称为<code>remote objects</code>，因为它们可以存储在Ray集群中的任何位置，我们使用引用来引用它们。Remote objects缓存在Ray的分布式共享内存对象存储中，集群中的每个节点都有一个对象存储。在集群设置中，remote objects可以存在于一个或多个节点上，与谁持有对象ref无关。</p>
<h2 id="Placement-Groups"><a href="#Placement-Groups" class="headerlink" title="Placement Groups"></a>Placement Groups</h2><p>Placement Groups允许用户自动地跨多个节点保留资源组(即，组调度)。然后，可以使用它们来调度Ray Task和Actor，它们按照位置(PACK)尽可能紧密地打包，或者分散(spread)。位置组通常用于安排Actor，但也支持Task。</p>
<h2 id="环境的依赖关系"><a href="#环境的依赖关系" class="headerlink" title="环境的依赖关系"></a>环境的依赖关系</h2><p>当Ray在远程机器上执行Task和Actor时，它们的环境依赖项(例如Python包、本地文件、环境变量)必须可用来运行代码。为了解决这个问题，你可以(1)使用Ray cluster Launcher提前准备你对集群的依赖，或者(2)使用Ray的运行时环境来动态安装它们。</p>
<h1 id><a href="#" class="headerlink" title="#"></a>#</h1>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Ray</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode 日记：背包问题</title>
    <url>/2022/04/01/Leetcode3/</url>
    <content><![CDATA[<h1 id="背包问题"><a href="#背包问题" class="headerlink" title="背包问题"></a>背包问题</h1><p>背包问题是一种组合优化的NP 完全问题：有N 个物品和容量为W 的背包，每个物品都有<br>自己的体积w 和价值v，求拿哪些物品可以使得背包所装下物品的总价值最大。如果限定每种物<br>品只能选择0 个或1 个，则问题称为0-1 背包问题；如果不限定每种物品的数量，则问题称为无<br>界背包问题或完全背包问题。</p>
<p>我们可以用动态规划来解决背包问题。以0-1 背包问题为例。我们可以定义一个二维数组dp<br>存储最大价值，其中dp[i][j] 表示前i 件物品体积不超过j 的情况下能达到的最大价值。在我们遍<br>历到第i 件物品时，在当前背包总容量为j 的情况下，如果我们不将物品i 放入背包，那么dp[i][j]<br>= dp[i-1][j]，即前i 个物品的最大价值等于只取前i-1 个物品时的最大价值；如果我们将物品i 放<br>入背包，假设第i 件物品体积为w，价值为v，那么我们得到dp[i][j] = dp[i-1][j-w] + v。我们只需在遍历过程中对这两种情况取最大值即可，总时间复杂度和空间复杂度都为O(NW)。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">knapsack</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; weights, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; values, <span class="keyword">int</span> N, <span class="keyword">int</span> W)</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; <span class="title">dp</span><span class="params">(N + <span class="number">1</span>, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(W + <span class="number">1</span>, <span class="number">0</span>))</span></span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= N; ++i)&#123;</span><br><span class="line">        <span class="keyword">int</span> w = weights[i<span class="number">-1</span>], v = values[i<span class="number">-1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= W; ++j)&#123;</span><br><span class="line">            <span class="keyword">if</span>(j &gt;= w)&#123;</span><br><span class="line">                dp[i][j] = max(dp[i<span class="number">-1</span>][j], dp[i<span class="number">-1</span>][j-w] + v);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                dp[i][j] = dp[i<span class="number">-1</span>][j];</span><br><span class="line">            &#125;        </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[N][W];</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/2022/04/01/Leetcode3/bb1.PNG" alt="bb1"></p>
<p>我们可以进一步对0-1 背包进行空间优化，将空间复杂度降低为O(W)。如图所示，假设我们目前考虑物品i = 2，且其体积为w = 2，价值为v = 3；对于背包容量j，我们可以得到dp[2][j] = max(dp[1][j], dp[1][j-2] + 3)。这里可以发现我们永远只依赖于上一排i = 1 的信息，之前算过的其他物品都不需要再使用。因此我们可以去掉dp 矩阵的第一个维度，在考虑物品i 时变成dp[j] = max(dp[j], dp[j-w] + v)。这里要注意我们在遍历每一行的时候必须逆向遍历，这样才能够调用上一行物品i-1 时dp[j-w] 的值；若按照从左往右的顺序进行正向遍历，则dp[j-w] 的值在遍历到 j 之前就已经被更新成物品i 的值了。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">knapsack</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; weights, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; values, <span class="keyword">int</span> N, <span class="keyword">int</span> W)</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">dp</span><span class="params">(W + <span class="number">1</span>, <span class="number">0</span>)</span></span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= N; ++i)&#123;</span><br><span class="line">        <span class="keyword">int</span> w = weights[i<span class="number">-1</span>], v = values[i<span class="number">-1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = W; j &gt;= w; --j)&#123;</span><br><span class="line">            dp[j] = max(dp[j], dp[j-w] + v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[W];</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/2022/04/01/Leetcode3/bb2.PNG" alt="bb2"></p>
<p>在完全背包问题中，一个物品可以拿多次。如图上半部分所示，假设我们遍历到物品i = 2，<br>且其体积为w = 2，价值为v = 3；对于背包容量j = 5，最多只能装下2 个该物品。那么我们的状<br>态转移方程就变成了dp[2][5] = max(dp[1][5], dp[1][3] + 3, dp[1][1] + 6)。如果采用这种方法，假设<br>背包容量无穷大而物体的体积无穷小，我们这里的比较次数也会趋近于无穷大，远超O(NW)的<br>时间复杂度。<br>怎么解决这个问题呢？我们发现在dp[2][3] 的时候我们其实已经考虑了dp[1][3] 和dp[2][1]<br>的情况，而在时dp[2][1] 也已经考虑了dp[1][1] 的情况。因此，如图下半部分所示，对于拿多个<br>物品的情况，我们只需考虑dp[2][3] 即可，即dp[2][5] = max(dp[1][5], dp[2][3] + 3)。这样，我们<br>就得到了完全背包问题的状态转移方程：dp[i][j] = max(dp[i-1][j], dp[i][j-w] + v)，其与0-1 背包问<br>题的差别仅仅是把状态转移方程中的第二个i-1 变成了i。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">knapsack</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; weights, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; values, <span class="keyword">int</span> N, <span class="keyword">int</span> W)</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; <span class="title">dp</span><span class="params">(N+<span class="number">1</span>, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(W+<span class="number">1</span>, <span class="number">0</span>))</span></span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= N; ++i)&#123;</span><br><span class="line">        <span class="keyword">int</span> w = weights[i<span class="number">-1</span>], v = velues[i<span class="number">-1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= W; ++j)&#123;</span><br><span class="line">            <span class="keyword">if</span>(j &gt;= w)&#123;</span><br><span class="line">                dp[i][j] = max(dp[i<span class="number">-1</span>][j], dp[i][j-w] + v);</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                dp[i][j] = dp[i<span class="number">-1</span>][j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[N][W];</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同样的，我们也可以利用空间压缩将时间复杂度降低为O(W)。这里要注意我们在遍历每一<br>行的时候必须正向遍历，因为我们需要利用当前物品在第j-w 列的信息。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">knapsack</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; weights, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; values, <span class="keyword">int</span> N, <span class="keyword">int</span> W)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">dp</span><span class="params">(W + <span class="number">1</span>, <span class="number">0</span>)</span></span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= N; ++i) &#123;</span><br><span class="line">        <span class="keyword">int</span> w = weights[i<span class="number">-1</span>], v = values[i<span class="number">-1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = w; j &lt;= W; ++j) &#123;</span><br><span class="line">            dp[j] = max(dp[j], dp[j-w] + v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[W];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>题</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
</search>
